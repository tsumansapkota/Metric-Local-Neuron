{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9e79740",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.mplot3d import Axes3D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d2b919f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import dtnnlib as dtnn\n",
    "\n",
    "from torchvision import datasets, transforms as T\n",
    "from torch.utils import data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24cf35cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.set_float32_matmul_precision('high')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53af51c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "import os, time, sys, random\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1602c6d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "mnist_transform = T.Compose([\n",
    "    T.ToTensor(),\n",
    "    T.Normalize(\n",
    "        mean=[0.5,],\n",
    "        std=[0.5,],\n",
    "    ),\n",
    "])\n",
    "\n",
    "train_dataset = datasets.FashionMNIST(root=\"data/\", train=True, download=True, transform=mnist_transform)\n",
    "test_dataset = datasets.FashionMNIST(root=\"data/\", train=False, download=True, transform=mnist_transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6807321",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 50\n",
    "train_loader = data.DataLoader(dataset=train_dataset, num_workers=4, batch_size=batch_size, shuffle=True)\n",
    "test_loader = data.DataLoader(dataset=test_dataset, num_workers=4, batch_size=batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd705fdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda:0\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0879c929",
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47582925",
   "metadata": {},
   "outputs": [],
   "source": [
    "for xx, yy in train_loader:\n",
    "    xx, yy = xx.to(device), yy.to(device)\n",
    "    print(xx.shape, yy.shape)\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "103909e2",
   "metadata": {},
   "source": [
    "## Any function as metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9551d612",
   "metadata": {},
   "outputs": [],
   "source": [
    "class FunctionDT(nn.Module):\n",
    "    \n",
    "    def __init__(self, input_dim, num_centers, func, inv_temp=1.):\n",
    "        '''\n",
    "        func [input_dim -> 1]\n",
    "        '''\n",
    "        super().__init__()\n",
    "        self.input_dim = input_dim\n",
    "        self.num_centers = num_centers\n",
    "        self.func = func\n",
    "        \n",
    "        self.inv_temp = nn.Parameter(torch.ones(1)*np.log(inv_temp))\n",
    "        \n",
    "        self.centers = torch.randn(num_centers, input_dim)/3.\n",
    "        self.centers = nn.Parameter(self.centers)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        z = x.unsqueeze(1) - self.centers.unsqueeze(0)\n",
    "        bs, h, dim = z.shape\n",
    "        z = z.view(-1, dim)\n",
    "#         print(z.shape, self.func(z).shape)\n",
    "        dists = self.func(z).view(bs, h)\n",
    "#         print(dists.shape)\n",
    "        dists = (1-dists)*torch.exp(self.inv_temp)\n",
    "        \n",
    "        return dists"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0484c29",
   "metadata": {},
   "outputs": [],
   "source": [
    "!git clone https://github.com/tsumansapkota/Input-Invex-Neural-Network.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e249d967",
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.path.append(\"Input-Invex-Neural-Network\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e1d6fbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "from classes import DistanceRegressor, ConvexNN\n",
    "from nflib.flows import SequentialFlow, ActNorm\n",
    "import nflib.res_flow as irf"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64d4fc66",
   "metadata": {},
   "source": [
    "## Merge all models into single and benchmark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffba015c",
   "metadata": {},
   "outputs": [],
   "source": [
    "models_keys = [\"l_0.5\", \"l_1\", \"l_2\", \"l_20\", \"stereo\", \"linear\",]\n",
    "def get_models(h = 5, key='linear'):\n",
    "    I = 784\n",
    "    layer1 = None\n",
    "    if key == \"l_0.5\":\n",
    "        layer1 = dtnn.DistanceTransform_Simple(I, h, p=0.5, bias=False)\n",
    "    elif key == \"l_1\":\n",
    "        layer1 = dtnn.DistanceTransform_Simple(I, h, p=1, bias=False)\n",
    "    elif key == \"l_2\":\n",
    "        layer1 = dtnn.DistanceTransform_Simple(I, h, bias=False)\n",
    "    elif key == \"l_20\":\n",
    "        layer1 = dtnn.DistanceTransform_Simple(I, h, p=20, bias=False)\n",
    "    elif key == \"stereo\":\n",
    "        layer1 = dtnn.iStereographicLinearTransform(I, h, bias=False)\n",
    "    elif key == \"linear\":\n",
    "        layer1 = nn.Linear(I, h, bias=False)\n",
    "    else:\n",
    "        raise KeyError()\n",
    "        \n",
    "    net = nn.Sequential(\n",
    "        layer1,\n",
    "        nn.BatchNorm1d(h, affine=False),\n",
    "        nn.LayerNorm(h),\n",
    "        nn.ELU(),\n",
    "        nn.Linear(h, 10),\n",
    "        )\n",
    "    return net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27c88089",
   "metadata": {},
   "outputs": [],
   "source": [
    "models_keys = []\n",
    "def get_models(h = 5, key='linear'):\n",
    "    return nn.Identity()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f2ae0c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_children(module):\n",
    "    child = list(module.children())\n",
    "    if len(child) == 0:\n",
    "        return [module]\n",
    "    children = []\n",
    "    for ch in child:\n",
    "        grand_ch = get_children(ch)\n",
    "        children+=grand_ch\n",
    "    return children\n",
    "\n",
    "def remove_spectral_norm(model):\n",
    "    for child in get_children(model):\n",
    "        if hasattr(child, 'weight'):\n",
    "            print(\"Yes\", child)\n",
    "            try:\n",
    "                irf.remove_spectral_norm_conv(child)\n",
    "                print(\"Success : irf conv\")\n",
    "            except Exception as e:\n",
    "                print(\"Failed : irf conv\")\n",
    "\n",
    "            try:\n",
    "                irf.remove_spectral_norm(child)\n",
    "                print(\"Success : irf lin\")\n",
    "            except Exception as e:\n",
    "                print(\"Failed : irf lin\")\n",
    "\n",
    "            try:\n",
    "                nn.utils.remove_spectral_norm(child)\n",
    "                print(\"Success : nn\")\n",
    "            except Exception as e:\n",
    "                print(\"Failed : nn\")\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14541096",
   "metadata": {},
   "outputs": [],
   "source": [
    "models_func_keys = [\"convex\", \"invex\", \"ordinary\"]\n",
    "\n",
    "def get_models_func(h = 500, func_h=500, key='ordinary'):\n",
    "#     I = 784\n",
    "    layer1 = None\n",
    "    if key == \"convex\":\n",
    "        layer1 = ConvexNN([784, func_h+2, func_h+1, 1])\n",
    "    elif key == \"invex\":\n",
    "        layer1 = nn.Sequential(\n",
    "                    ActNorm(784),\n",
    "                    irf.ResidualFlow(784, [func_h, func_h], activation=irf.LeakyReLU),\n",
    "                    ActNorm(784),\n",
    "                    DistanceRegressor(784),\n",
    "                    )\n",
    "    elif key == \"ordinary\":\n",
    "        layer1 = nn.Sequential(\n",
    "                    ActNorm(784),\n",
    "                    irf.ResidualFlow(784, [func_h, func_h], activation=irf.LeakyReLU),\n",
    "                    ActNorm(784),\n",
    "                    DistanceRegressor(784),\n",
    "                    )\n",
    "        remove_spectral_norm(layer1)\n",
    "    else:\n",
    "        raise KeyError()\n",
    "        \n",
    "    net = nn.Sequential(\n",
    "        FunctionDT(784, h, layer1),\n",
    "        nn.BatchNorm1d(h, affine=False),\n",
    "        nn.LayerNorm(h),\n",
    "        nn.ELU(),\n",
    "        nn.Linear(h, 10),\n",
    "        )\n",
    "    return net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9eaa0286",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Following is copied from \n",
    "### https://github.com/kuangliu/pytorch-cifar/blob/master/main.py\n",
    "\n",
    "# Training\n",
    "def train(epoch, model, optimizer):\n",
    "    model.train()\n",
    "    train_loss = 0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    for batch_idx, (inputs, targets) in enumerate(train_loader):\n",
    "        inputs, targets = inputs.to(device).view(-1, 28*28), targets.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, targets)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        train_loss += loss.item()\n",
    "        _, predicted = outputs.max(1)\n",
    "        total += targets.size(0)\n",
    "        correct += predicted.eq(targets).sum().item()\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7bd80c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_acc = -1\n",
    "def test(epoch, model, model_name):\n",
    "    global best_acc\n",
    "    model.eval()\n",
    "    test_loss = 0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        for batch_idx, (inputs, targets) in enumerate(test_loader):\n",
    "            inputs, targets = inputs.to(device).view(-1, 28*28), targets.to(device)\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, targets)\n",
    "\n",
    "            test_loss += loss.item()\n",
    "            _, predicted = outputs.max(1)\n",
    "            total += targets.size(0)\n",
    "            correct += predicted.eq(targets).sum().item()\n",
    "            \n",
    "    acc = 100.*correct/total\n",
    "    if acc > best_acc:\n",
    "        state = {\n",
    "            'model': model.state_dict(),\n",
    "            'acc': acc,\n",
    "            'epoch': epoch,\n",
    "        }\n",
    "        best_acc = acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e46396d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 0.0001\n",
    "EPOCHS = 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0feb854",
   "metadata": {},
   "outputs": [],
   "source": [
    "H = [5, 10, 20, 100, 500]\n",
    "\n",
    "models_keys, models_func_keys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2712ff5",
   "metadata": {},
   "outputs": [],
   "source": [
    "exp_acc_vals = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1c2b243",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Opening JSON file\n",
    "try:\n",
    "    with open(\"./outputs/03_exp_acc_data_LN_BN.json\", 'r') as f:\n",
    "        exp_acc_vals = json.load(f)\n",
    "except:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a599a22",
   "metadata": {},
   "outputs": [],
   "source": [
    "exp_acc_vals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7278a22d",
   "metadata": {},
   "outputs": [],
   "source": [
    "SEEDS = [147, 258, 369, 741, 852, 963, 159, 357]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9790938",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Initialization\n",
    "for h in H:\n",
    "    acc_dict = {}\n",
    "    for key, func_idx in zip(models_keys+models_func_keys, [0]*len(models_keys)+[1]*len(models_func_keys)):\n",
    "        print(f\"Checking for {key} ; h:{h}\")\n",
    "        try:\n",
    "            results = exp_acc_vals[str(h)][str(key)]\n",
    "            print(results)\n",
    "            if len(results) == len(SEEDS):\n",
    "                print(\"Results found complete\")\n",
    "                acc_dict[str(key)] = results\n",
    "                continue\n",
    "        except Exception as e:\n",
    "            pass\n",
    "        acc_dict[str(key)] = []\n",
    "    exp_acc_vals[str(h)] = acc_dict\n",
    "exp_acc_vals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e0f26a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# asdsad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bea674cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "for h in H:\n",
    "    acc_dict = exp_acc_vals[str(h)]\n",
    "    \n",
    "    for key, func_idx in zip(models_keys+models_func_keys, [0]*len(models_keys)+[1]*len(models_func_keys)):\n",
    "        print(\"_________________________\")\n",
    "        print(f\"Experimenting for {key} ; h:{h}\")\n",
    "        \n",
    "        try:\n",
    "            results = exp_acc_vals[str(h)][str(key)]\n",
    "            print(results)\n",
    "            if len(results) == len(SEEDS):\n",
    "                print(\"Results found complete\")\n",
    "                acc_dict[str(key)] = results\n",
    "                continue\n",
    "        except Exception as e:\n",
    "            pass\n",
    "\n",
    "        acc_dict[str(key)] = []\n",
    "        for seed in tqdm(SEEDS):\n",
    "            model_name = f\"03_fmnist_{key}_h{h}_s{seed}\"\n",
    "            \n",
    "            torch.manual_seed(seed)\n",
    "            np.random.seed(seed)\n",
    "            random.seed(seed)\n",
    "            train_loader = data.DataLoader(dataset=train_dataset, num_workers=4, batch_size=batch_size, shuffle=True)\n",
    "            test_loader = data.DataLoader(dataset=test_dataset, num_workers=4, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "            if func_idx == 0:\n",
    "                net = get_models(h, key=key).to(device)\n",
    "            else:\n",
    "                net = get_models_func(h, key=key).to(device)\n",
    "            \n",
    "            optimizer = torch.optim.Adam(net.parameters(), lr=learning_rate)\n",
    "            scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=EPOCHS)\n",
    "            best_acc = -1\n",
    "#             for epoch in tqdm(range(EPOCHS)):\n",
    "            for epoch in range(EPOCHS):\n",
    "#             for epoch in range(1):\n",
    "                train(epoch, net, optimizer)\n",
    "                test(epoch, net, model_name)\n",
    "                scheduler.step()\n",
    "            acc_dict[str(key)] += [float(best_acc)] ## add to the list\n",
    "        \n",
    "        exp_acc_vals[str(h)] = acc_dict\n",
    "        \n",
    "        # Save it in the file.\n",
    "        with open(f\"./outputs/03_exp_acc_data_LN_BN.json\", \"w\") as f:\n",
    "            json.dump(exp_acc_vals, f, indent=3)\n",
    "        \n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76cf1156",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import json\n",
    "# with open(\"./outputs/03_exp_acc_data_LN_BN.json\", 'r') as f:\n",
    "#     exp_acc_vals = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da496a19",
   "metadata": {},
   "outputs": [],
   "source": [
    "exp_acc_vals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aaeb784e",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_stats = {}\n",
    "for h in exp_acc_vals:\n",
    "    final_stats[h] = {}\n",
    "    for key in exp_acc_vals[h]:\n",
    "        data = exp_acc_vals[h][key]\n",
    "        mean = np.mean(data)\n",
    "        std = np.std(data)\n",
    "        maxm = np.max(data)\n",
    "        final_stats[h][key] = [np.round(mean, 2), np.round(std, 2), np.round(maxm, 2)]\n",
    "final_stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f1d3ea0",
   "metadata": {},
   "outputs": [],
   "source": [
    "for h in H:\n",
    "    for key, func_idx in zip(models_keys+models_func_keys, [0]*len(models_keys)+[1]*len(models_func_keys)):\n",
    "#     for key, func_idx in zip(models_func_keys, [1]*len(models_func_keys)):\n",
    "        print(\"_________________________\")\n",
    "        print(f\"Testing for {key} ; h:{h}\")\n",
    "        if func_idx == 0:\n",
    "            net = get_models(h, key=key).to(device)\n",
    "        else:\n",
    "            net = get_models_func(h, key=key).to(device)\n",
    "        print(\"Params:\", sum([p.numel() for p in net.parameters()]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c480e5f8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
