{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import copy\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "import matplotlib\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "import dtnnlib as dtnn\n",
    "\n",
    "%matplotlib inline\n",
    "matplotlib.rcParams['figure.figsize'] = (9, 8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# device = torch.device(\"cuda:0\")\n",
    "device = torch.device(\"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DistanceTransform_Epsilon(dtnn.DistanceTransformBase):\n",
    "    \n",
    "    def __init__(self, input_dim, num_centers, p=2, bias=False, epsilon=0.1, itemp=1):\n",
    "        super().__init__(input_dim, num_centers, p=2)\n",
    "        \n",
    "        nc = num_centers\n",
    "        self.scaler = nn.Parameter(torch.log(torch.ones(1, 1)*itemp))\n",
    "        if epsilon is not None:\n",
    "            nc += 1\n",
    "        self.bias = nn.Parameter(torch.ones(1, nc)*0) if bias else None\n",
    "        self.epsilon = epsilon\n",
    "        \n",
    "    def forward(self, x):\n",
    "        dists = super().forward(x)\n",
    "        \n",
    "        if self.epsilon is not None:\n",
    "            #################################\n",
    "            dists = torch.cat([dists, torch.ones(len(x), 1).to(x)*self.epsilon], dim=1)\n",
    "            #################################\n",
    "        \n",
    "        ## scale the dists (1 is optional)\n",
    "        dists = 1-dists*torch.exp(self.scaler)\n",
    "    \n",
    "        if self.bias is not None: dists = dists+self.bias\n",
    "        return dists"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DistanceTransform_minExp_Epsilon(dtnn.DistanceTransformBase):\n",
    "    \n",
    "    def __init__(self, input_dim, num_centers, p=2, bias=False, epsilon=0.1, itemp=1):\n",
    "        super().__init__(input_dim, num_centers, p=2)\n",
    "        \n",
    "        nc = num_centers\n",
    "        self.scaler = nn.Parameter(torch.log(torch.ones(1, 1)*itemp))\n",
    "        if epsilon is not None:\n",
    "            nc += 1\n",
    "        self.bias = nn.Parameter(torch.ones(1, nc)*0) if bias else None\n",
    "        self.epsilon = epsilon\n",
    "        \n",
    "    def forward(self, x):\n",
    "        dists = super().forward(x)\n",
    "        \n",
    "        if self.epsilon is not None:\n",
    "            #################################\n",
    "            dists = torch.cat([dists, torch.ones(len(x), 1).to(x)*self.epsilon], dim=1)\n",
    "            #################################\n",
    "        \n",
    "        dists = dists-dists.min(dim=1, keepdim=True)[0]\n",
    "        dists = torch.exp(-dists*self.scaler)\n",
    "    \n",
    "        if self.bias is not None: dists = dists+self.bias\n",
    "        return dists"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LocalMLP_epsilonsoftmax(nn.Module):\n",
    "    \n",
    "    def __init__(self, input_dim, hidden_dim, output_dim, epsilon=1.0, itemp=1):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.input_dim = input_dim\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.new_hidden_dim = 0\n",
    "        self.output_dim = output_dim\n",
    "        \n",
    "        self.layer0 = DistanceTransform_Epsilon(self.input_dim, self.hidden_dim, bias=False, epsilon=epsilon, itemp=itemp)\n",
    "        \n",
    "        hdim = self.hidden_dim\n",
    "        if epsilon is not None:\n",
    "            hdim += 1\n",
    "            \n",
    "        self.softmax = nn.Softmax(dim=-1)\n",
    "        self.layer1 = nn.Linear(hdim, self.output_dim)\n",
    "    \n",
    "        self.temp_maximum = None\n",
    "        \n",
    "    def forward(self, x):\n",
    "        xo = self.layer0(x)\n",
    "\n",
    "        ## drouout here is suitable for activation function (the probabilities do not add upto 1)\n",
    "#         xo = F.dropout(xo, p=0.1, training=self.training)\n",
    "\n",
    "        xo = self.softmax(xo)\n",
    "        self.temp_maximum = xo.data\n",
    "        \n",
    "#         if self.training: ## to not use epsilon Neuron\n",
    "#             self.layer1.weight.data[:,-1]*=0.\n",
    "        xo = self.layer1(xo)\n",
    "        return xo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LocalMLP_unNormalized(nn.Module):\n",
    "    \n",
    "    def __init__(self, input_dim, hidden_dim, output_dim, epsilon=1.0, itemp=1):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.input_dim = input_dim\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.new_hidden_dim = 0\n",
    "        self.output_dim = output_dim\n",
    "        \n",
    "        self.layer0 = DistanceTransform_minExp_Epsilon(self.input_dim, self.hidden_dim, bias=False, epsilon=epsilon, itemp=itemp)\n",
    "        \n",
    "        hdim = self.hidden_dim\n",
    "        if epsilon is not None:\n",
    "            hdim += 1\n",
    "            \n",
    "        self.softmax = nn.Identity()\n",
    "        self.layer1 = nn.Linear(hdim, self.output_dim)\n",
    "    \n",
    "        self.temp_maximum = None\n",
    "        \n",
    "    def forward(self, x):\n",
    "        xo = self.layer0(x)\n",
    "        xo = self.softmax(xo)\n",
    "        \n",
    "        self.temp_maximum = xo.data\n",
    "        xo = self.layer1(xo)\n",
    "        return xo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def twospirals(n_points, noise=.5, angle=784):\n",
    "    \"\"\"\n",
    "     Returns the two spirals dataset.\n",
    "    \"\"\"\n",
    "    n = np.sqrt(np.random.rand(n_points,1)) * angle * (2*np.pi)/360\n",
    "    d1x = -np.cos(n)*n + np.random.rand(n_points,1) * noise\n",
    "    d1y = np.sin(n)*n + np.random.rand(n_points,1) * noise\n",
    "    return (np.vstack((np.hstack((d1x,d1y)),np.hstack((-d1x,-d1y)))), \n",
    "            np.hstack((np.zeros(n_points),np.ones(n_points))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(1)\n",
    "x, y = twospirals(300, angle=560)\n",
    "x, y = x/x.max(axis=0, keepdims=True), y.reshape(-1)\n",
    "xx, yy = torch.FloatTensor(x), torch.FloatTensor(y.reshape(-1,1))\n",
    "\n",
    "x1 = xx[:,0]\n",
    "x2 = xx[:,1]\n",
    "\n",
    "%matplotlib inline\n",
    "plt.figure(figsize=(5,5))\n",
    "plt.scatter(x1, x2, c=y, marker='.')\n",
    "# plt.xlabel(\"x1\")\n",
    "# plt.ylabel(\"x2\")\n",
    "plt.axis(\"equal\")\n",
    "# plt.savefig(\"./clf_toy_data.pdf\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xx, yy = xx.to(device), yy.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Choose Model Here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.BCELoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "H = 15\n",
    "### parameters are changed later to visualize the effects..\n",
    "model = LocalMLP_epsilonsoftmax(2, H, 1, epsilon=0.1)\n",
    "model = LocalMLP_unNormalized(2, H, 1, epsilon=0.1)\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.layer0.scaler.data[0,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.layer0.scaler.data[0,0] = 3. ## can change the scale here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(1)\n",
    "randidx = torch.randperm(len(xx))[:H]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.layer0.centers.data = xx[randidx] \n",
    "\n",
    "## Mapping like MLP\n",
    "out = (yy[randidx].t()*2-1)*1.0\n",
    "\n",
    "## For epsilon\n",
    "if model.layer0.epsilon is not None:\n",
    "    out = torch.cat([out, torch.ones(1, 1)*0.], dim=1)\n",
    "\n",
    "model.layer1.weight.data = out\n",
    "model.layer1.bias.data *= 0.\n",
    "\n",
    "yout = torch.sigmoid(model(xx))\n",
    "loss = criterion(yout, yy)\n",
    "accuracy = ((yout>0.5).type(torch.float32) == yy).type(torch.float).mean()\n",
    "loss.item(), accuracy.item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "yout = torch.sigmoid(model(xx))\n",
    "ax = plt.figure(figsize=(6,5)).add_subplot()\n",
    "out = (yout.data.cpu().numpy()>0.5).astype(int)\n",
    "ax.scatter(x1, x2, c=out, marker= '.', alpha=0.3)\n",
    "## plot centroids\n",
    "c = model.layer0.centers.data.cpu()\n",
    "d = model.layer1.weight.data.cpu().t() #+ net.net[-1].bias.data.cpu()\n",
    "\n",
    "for i in range(c.shape[0]):\n",
    "    color = matplotlib.cm.tab20(i%20)\n",
    "    ax.arrow(c[i,0], c[i,1], d[i,0], 0, head_width=0.15, head_length=0.1, fc=color, ec=color, linestyle=(0, (5, 10)))\n",
    "    ax.scatter(c[i,0], c[i,1], color=color, marker= 'x')\n",
    "    \n",
    "# plt.tick_params(left = False, right = False , labelleft = False ,\n",
    "#                 labelbottom = False, bottom = False)\n",
    "plt.xlim(-1.9, 1.8)\n",
    "plt.ylim(-2.2, 1.8)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "yout.shape, out.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "yout = model(xx)\n",
    "ax = plt.figure(figsize=(6,5)).add_subplot()\n",
    "out = (yout.data.cpu().numpy()>0.0).astype(int)\n",
    "\n",
    "ax.scatter(x1, x2, c=out, marker= 'p', alpha=0.1)\n",
    "\n",
    "ax.scatter(yout[:,0].data.numpy(), x2, c=out, marker= '.', alpha=1.0, cmap=\"coolwarm\")\n",
    "## plot centroids\n",
    "c = model.layer0.centers.data.cpu()\n",
    "d = model.layer1.weight.data.cpu().t() #+ net.net[-1].bias.data.cpu()\n",
    "\n",
    "for i in range(c.shape[0]):\n",
    "    color = matplotlib.cm.tab20(i%20)\n",
    "    ax.arrow(c[i,0], c[i,1], d[i,0], 0, head_width=0.15, head_length=0.1, fc=color, ec=color, linestyle=(0, (5, 10)))\n",
    "    ax.scatter(c[i,0], c[i,1], color=color, marker= 'x')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modify Here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.layer0.epsilon = None #### None #1. #0.3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.layer0.scaler.data[0,0] = 2.0 #### 0.5 # 2.0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Visualize the confidence per neuron in a grid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def forward_intermediate(self, x):\n",
    "    xo = self.layer0(x)\n",
    "    xo = self.softmax(xo).data\n",
    "    return xo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xo = forward_intermediate(model, xx)\n",
    "\n",
    "print(xo.shape)\n",
    "print(xo.mean(dim=0), \"\\n \", xo.std(dim=0))\n",
    "print(xo.min(dim=0)[0], \"\\n \", xo.max(dim=0)[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_points = 1000\n",
    "X1 = np.linspace(-1.5, 1.5, num_points)*2\n",
    "X2 = np.linspace(-1.5, 1.5, num_points)*2\n",
    "X1, X2 = np.meshgrid(X1, X2)\n",
    "\n",
    "XX = torch.Tensor(np.c_[X1.reshape(-1), X2.reshape(-1)]).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "YY = forward_intermediate(model, XX)\n",
    "if model.layer0.epsilon is None:\n",
    "    YY = YY.reshape(num_points, num_points, H) ## for non-epsilon\n",
    "else:\n",
    "    YY = YY.reshape(num_points, num_points, H+1) ## for epsilon\n",
    "YY.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_actv = forward_intermediate(model, model.layer0.centers.data.cpu())\n",
    "max_actv = max_actv.diag().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!mkdir outputs/13_local_neuron_region"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for idx in range(xo.shape[1]):\n",
    "    conf = YY[:,:,idx]\n",
    "    conf = conf.data.cpu().numpy().reshape(X1.shape)\n",
    "    print(conf.shape)\n",
    "    \n",
    "    ax = plt.figure(figsize=(8,8)).add_subplot()\n",
    "\n",
    "    ax.scatter(x1, x2, c=out, marker= '.', alpha=0.3)\n",
    "\n",
    "    ## plot centroids\n",
    "    c = model.layer0.centers.data.cpu()\n",
    "    for i in range(c.shape[0]):\n",
    "        color = matplotlib.cm.tab20(i%20)\n",
    "        ax.scatter(c[i,0], c[i,1], color=color, marker= 'x', s=100)\n",
    "    \n",
    "    try:\n",
    "        ax.scatter(c[idx,0], c[idx,1], color=\"k\", marker= 'X', s=100)\n",
    "        print(f\"center:\",max_actv[idx],\"max_grid:\",conf.max(), max_actv[idx] >= conf.max())\n",
    "    except:\n",
    "        pass\n",
    "    \n",
    "    maxpt = XX[conf.argmax()]\n",
    "    ax.scatter(maxpt[0], maxpt[1], color=\"r\", marker= 'o', s=100)\n",
    "    \n",
    "    plt.imshow(conf, interpolation='nearest',\n",
    "           extent=(X1.min(), X1.max(), X2.min(), X2.max()),\n",
    "           alpha=0.6, cmap='gray',\n",
    "           aspect='auto', origin='lower')\n",
    "    \n",
    "    LVLs = 20\n",
    "    cs = ax.contour(X1, X2, conf, levels=LVLs, linestyles=\"None\", colors=\"k\", linewidths=1, zorder=-2)\n",
    "    ax.clabel(cs, cs.levels, inline=True, fontsize=8, fmt=\"%1.2f\")\n",
    "    \n",
    "    model_name = \"\"\n",
    "    if isinstance(model, LocalMLP_unNormalized):\n",
    "        model_name = \"unnormalized_mindistexp\"\n",
    "    else:\n",
    "        model_name = \"dtSM\"\n",
    "    if model.layer0.epsilon is not None:\n",
    "        model_name += f\"_e{model.layer0.epsilon}\"\n",
    "    model_name+= f\"_s{float(model.layer0.scaler.data[0,0]):.2f}\"\n",
    "    \n",
    "    \n",
    "    plt.savefig(f\"./outputs/13_local_neuron_region/{model_name}_neuron_{idx}.pdf\", bbox_inches=\"tight\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
