{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import copy\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "import matplotlib\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import dtnnlib as dtnn\n",
    "\n",
    "%matplotlib inline\n",
    "matplotlib.rcParams['figure.figsize'] = (9, 8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# device = torch.device(\"cuda:0\")\n",
    "device = torch.device(\"cpu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Building 2D model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(1)\n",
    "def twospirals(n_points, noise=.5, angle=784):\n",
    "    \"\"\"\n",
    "     Returns the two spirals dataset.\n",
    "    \"\"\"\n",
    "    n = np.sqrt(np.random.rand(n_points,1)) * angle * (2*np.pi)/360\n",
    "    d1x = -np.cos(n)*n + np.random.rand(n_points,1) * noise\n",
    "    d1y = np.sin(n)*n + np.random.rand(n_points,1) * noise\n",
    "    return (np.vstack((np.hstack((d1x,d1y)),np.hstack((-d1x,-d1y)))), \n",
    "            np.hstack((np.zeros(n_points),np.ones(n_points))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x, y = twospirals(300, angle=560)\n",
    "x, y = x/x.max(axis=0, keepdims=True), y.reshape(-1)\n",
    "xx, yy = torch.FloatTensor(x), torch.FloatTensor(y.reshape(-1,1))\n",
    "\n",
    "x1 = xx[:,0]\n",
    "x2 = xx[:,1]\n",
    "\n",
    "%matplotlib inline\n",
    "plt.figure(figsize=(5,5))\n",
    "plt.scatter(x1, x2, c=y, marker='.')\n",
    "# plt.savefig(\"./clf_toy_data.pdf\")\n",
    "plt.xlabel(\"x1\")\n",
    "plt.ylabel(\"x2\")\n",
    "plt.axis(\"equal\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xx, yy = xx.to(device), yy.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Distance Based Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DistanceTransform_Epsilon(dtnn.DistanceTransformBase):\n",
    "    \n",
    "    def __init__(self, input_dim, num_centers, p=2, bias=False, epsilon=0.1):\n",
    "        super().__init__(input_dim, num_centers, p=2)\n",
    "        \n",
    "        nc = num_centers\n",
    "        if epsilon is not None:\n",
    "            nc += 1\n",
    "        self.scaler = nn.Parameter(torch.log(torch.ones(1, 1)*1))\n",
    "\n",
    "        self.bias = nn.Parameter(torch.ones(1, nc)*0) if bias else None\n",
    "        self.epsilon = epsilon\n",
    "        \n",
    "    def forward(self, x):\n",
    "        dists = super().forward(x)\n",
    "        \n",
    "        if self.epsilon is not None:\n",
    "            dists = torch.cat([dists, torch.ones(len(x), 1, dtype=x.dtype)*self.epsilon], dim=1)\n",
    "        \n",
    "        dists = -dists\n",
    "        dists = dists/np.sqrt(dists.shape[1])\n",
    "        dists = dists*torch.exp(self.scaler)\n",
    "\n",
    "        if self.bias is not None: dists = dists+self.bias\n",
    "        return dists"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DT_epsilon_Classifier(DistanceTransform_Epsilon):\n",
    "    \n",
    "    def __init__(self, input_dim, output_dim, bias=True, epsilon=1.0):\n",
    "        super().__init__(input_dim, output_dim, bias=bias, epsilon=epsilon)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        xo = super().forward(x)\n",
    "#         return xo[:, :-1]\n",
    "        return F.softmax(xo, dim=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def log_nll_loss(output, target):\n",
    "    return F.nll_loss(torch.log(output), target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "yy = yy.reshape(-1).type(torch.LongTensor)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### DTeSM Residual "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DTeSM(DistanceTransform_Epsilon):\n",
    "    \n",
    "    def __init__(self, input_dim, output_dim, bias=True, epsilon=1.0, itemp=10):\n",
    "        ### NOTE: Here, not using bias leads to more uniform centroid activation, and easy to compare..\n",
    "        super().__init__(input_dim, output_dim, bias=bias, epsilon=epsilon)\n",
    "        \n",
    "        self.scale_shift = dtnn.ScaleShift(-1, scaler_init=itemp, shifter_init=0, scaler_const=True, shifter_const=True)\n",
    "        self.softmax = nn.Softmax(dim=-1)\n",
    "        self.temp_activ = None\n",
    "        \n",
    "    def forward(self, x):\n",
    "        xo = super().forward(x)\n",
    "        xo = self.scale_shift(xo)\n",
    "        xo = self.softmax(xo)\n",
    "        self.temp_activ = xo.data\n",
    "#         return xo[:, :-1]\n",
    "        return xo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LocalMLP_DTeSM(nn.Module):\n",
    "\n",
    "    def __init__(self, input_dim, hidden_dim, output_dim, epsilon=None, itemp=1.0):\n",
    "        super().__init__()\n",
    "        self.layer0 = DTeSM(input_dim, hidden_dim, True, epsilon, itemp)\n",
    "        if epsilon is not None:\n",
    "            hidden_dim += 1\n",
    "        self.layer1 = nn.Linear(hidden_dim, output_dim)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.layer0(x)\n",
    "        x = self.layer1(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LocalResidual_DTeSM(nn.Module):\n",
    "    \n",
    "    def __init__(self, input_dim, hidden_dim, epsilon=None, itemp=1.0):\n",
    "        super().__init__()\n",
    "        self.layer0 = DTeSM(input_dim, hidden_dim, True, epsilon, itemp)\n",
    "        if epsilon is not None:\n",
    "            hidden_dim += 1\n",
    "        self.layer1 = nn.Linear(hidden_dim, input_dim)\n",
    "        self.layer1.bias.data *= 0.\n",
    "        \n",
    "    def forward(self, x):\n",
    "        h = self.layer0(x)\n",
    "        h = x + self.layer1(h)\n",
    "        return h"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Optimize Classifier to Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = DT_epsilon_Classifier(2, 2, epsilon=1.0)\n",
    "# model = DT_epsilon_Classifier(2, 2, epsilon=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = log_nll_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### ASSUMING: first half is class 0 and second half is class 1\n",
    "cls_randidx = torch.randint(len(yy)//2, (2,))+torch.LongTensor([0, len(yy)//2])\n",
    "model.centers.data = xx[cls_randidx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "yout = model(xx)\n",
    "loss = criterion(yout, yy)\n",
    "\n",
    "accuracy = (yout.max(dim=1)[1] == yy).type(torch.float).mean()                \n",
    "print(f'Acc:{float(accuracy):.2f}, Loss:{float(loss)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_bkp = float(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = plt.figure(figsize=(6,6)).add_subplot()\n",
    "out = yout.max(dim=1)[1].data.cpu().numpy()\n",
    "ax.scatter(x1, x2, c=out, marker= '.')\n",
    "## plot centroids\n",
    "c = model.centers.data.cpu()\n",
    "ax.scatter(c[:,0], c[:,1], ec='k', fc='r', marker= 'X', s=100)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#############################\n",
    "### Development of replacing centers per class\n",
    "STEPS = 100\n",
    "for steps in range(STEPS):\n",
    "    for i in range(2):## for each class\n",
    "        backup_center = copy.deepcopy(model.centers.data)\n",
    "        cls_randidx = torch.randint(len(yy)//2, (1,))[0] + i*len(yy)//2\n",
    "        model.centers.data[i] = xx[cls_randidx]\n",
    "\n",
    "        yout = model(xx)\n",
    "        loss = criterion(yout, yy)\n",
    "        accuracy = (yout.max(dim=1)[1] == yy).type(torch.float).mean()                \n",
    "        if loss > loss_bkp:\n",
    "            model.centers.data = backup_center\n",
    "        else:\n",
    "            loss_bkp = float(loss)\n",
    "        \n",
    "    if (steps+1)%10 == 0:\n",
    "        yout = model(xx)\n",
    "        loss = criterion(yout, yy)\n",
    "        accuracy = (yout.max(dim=1)[1] == yy).type(torch.float).mean()                \n",
    "        ax = plt.figure(figsize=(6,6)).add_subplot()\n",
    "        out = yout.max(dim=1)[1].data.cpu().numpy()\n",
    "        ax.scatter(x1, x2, c=out, marker= '.')\n",
    "        ## plot centroids\n",
    "        c = model.centers.data.cpu()\n",
    "        ax.scatter(c[:,0], c[:,1], ec='k', fc='r', marker= 'X', s=100)\n",
    "        plt.show()\n",
    "        print(f'Acc:{float(accuracy):.2f}, Loss:{float(loss)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_points = 1000\n",
    "X1 = np.linspace(-1.5, 1.5, num_points)*2\n",
    "X2 = np.linspace(-1.5, 1.5, num_points)*2\n",
    "X1, X2 = np.meshgrid(X1, X2)\n",
    "\n",
    "XX = torch.Tensor(np.c_[X1.reshape(-1), X2.reshape(-1)]).to(device)\n",
    "XX.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Repeat below after changing parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "YY = model(XX)\n",
    "YY = YY.reshape(num_points, num_points, -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "yout = model(xx)\n",
    "out = yout.max(dim=1)[1].data.cpu().numpy()\n",
    "accuracy = (yout.max(dim=1)[1] == yy).type(torch.float).mean()\n",
    "accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_actv = model(model.centers.data).data.cpu()\n",
    "max_actv = max_actv.diag().numpy()\n",
    "max_actv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for idx in range(YY.shape[-1]):\n",
    "    conf = YY[:,:,idx]\n",
    "    conf = conf.data.cpu().numpy().reshape(X1.shape)\n",
    "    \n",
    "    ax = plt.figure(figsize=(6,6)).add_subplot()\n",
    "    ax.scatter(x1, x2, c=out, marker= '.', alpha=0.3)\n",
    "\n",
    "    ## plot centroids\n",
    "    c = model.centers.data.cpu()\n",
    "    for i in range(c.shape[0]):\n",
    "        color = matplotlib.cm.tab20(i%20)\n",
    "        ax.scatter(c[i,0], c[i,1], color=color, marker= 'x', s=100)\n",
    "    \n",
    "    try:\n",
    "        ax.scatter(c[idx,0], c[idx,1], color=\"k\", marker= 'X', s=100)\n",
    "        print(f\"center:\",max_actv[idx],\"max_grid:\",conf.max(), max_actv[idx] >= conf.max())\n",
    "    except:\n",
    "        pass\n",
    "    \n",
    "    maxpt = XX[conf.argmax()]\n",
    "    ax.scatter(maxpt[0], maxpt[1], color=\"r\", marker= 'o', s=100)\n",
    "    \n",
    "    plt.imshow(conf, interpolation='nearest',\n",
    "           extent=(X1.min(), X1.max(), X2.min(), X2.max()),\n",
    "           alpha=0.6, cmap='gray',\n",
    "           aspect='auto', origin='lower')\n",
    "    \n",
    "    LVLs = 20\n",
    "#     LVLs = torch.linspace(0.0, 0.99, 20)\n",
    "    cs = ax.contour(X1, X2, conf, levels=LVLs, linestyles=\"None\", colors=\"k\", linewidths=1, zorder=-2)\n",
    "    ax.clabel(cs, cs.levels, inline=True, fontsize=8, fmt=\"%1.2f\")\n",
    "    \n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.bias.data, model.scaler, torch.exp(model.scaler)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Changing parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.bias.data[0] = torch.Tensor([0, 0, -1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.scaler.data[0,0] = 2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier = model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Optimize Local Res-MLP center noisy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tt_0 = classifier.centers.data[yy]\n",
    "tt_0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "H0 = 20\n",
    "N_search0 = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "residual0 = LocalResidual_DTeSM(2, H0, epsilon=0.4, itemp=7.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "residual0.layer0.scaler.data[0,0] = 2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "residual0.layer1.weight.data[:, -1] = residual0.layer1.weight.data[:, -1]*0 ### zero out epsilon.."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "residual0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "residual0.layer1.bias.data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## random init\n",
    "randidx = torch.randperm(len(xx))[:H0]\n",
    "residual0.layer0.centers.data = xx[randidx] \n",
    "\n",
    "diff = tt_0[randidx] - residual0.layer0.centers.data - residual0.layer1.bias.data\n",
    "residual0.layer1.weight.data[:, :H0] = diff.t()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Visualize neurons -- code below "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Visualize Neurons (jump to code)](#Visualize-Neurons)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# asdasdasd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Add Neurons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_neurons_to_residual(model, centers, values):\n",
    "    c = torch.cat((model.layer0.centers.data, centers), dim=0)\n",
    "    if model.layer0.epsilon is None:\n",
    "        v = torch.cat((model.layer1.weight.data, values.t()), dim=1)\n",
    "        s = torch.cat([model.layer0.bias.data, torch.ones(1, len(centers))*0], dim=1)\n",
    "    else:\n",
    "        v = torch.cat((model.layer1.weight.data[:,:-1], values.t(), model.layer1.weight.data[:,-1:]), dim=1)\n",
    "        s = torch.cat([model.layer0.bias.data[:,:-1], torch.ones(1, len(centers))*0, model.layer0.bias.data[:,-1:]], dim=1)\n",
    "        \n",
    "    model.layer0.centers.data = c\n",
    "    model.layer1.weight.data = v\n",
    "    model.layer0.bias.data = s\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "randidx = torch.randperm(len(xx))[:N_search0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shift_by = tt_0[randidx] - xx[randidx] - residual0.layer1.bias.data\n",
    "# add_neurons_to_residual(residual0, xx[randidx], shift_by)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    h1 = residual0(xx)\n",
    "    yout = classifier(h1)\n",
    "accuracy = (yout.max(dim=1)[1] == yy).type(torch.float).mean()\n",
    "accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Visualize Neurons (jump to code)](#Visualize-Neurons)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prune Neurons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_neurons_from_residual(model, importance, num_prune):\n",
    "    N = model.layer0.centers.shape[0]\n",
    "    importance = importance[:N]\n",
    "    topk_idx = torch.topk(importance, k=N-num_prune, largest=True)[1]\n",
    "    removing = torch.topk(importance, k=num_prune, largest=False)[1]\n",
    "    print(f\"Removing:\\n{removing.data.sort()[0]}\")\n",
    "    \n",
    "    c = model.layer0.centers.data[topk_idx]\n",
    "    ## modifying for value tensor and bias (for epsilon value)\n",
    "    if model.layer0.epsilon is not None:\n",
    "        topk_idx = torch.cat([topk_idx, torch.tensor([N], dtype=topk_idx.dtype)])\n",
    "    s = model.layer0.bias.data[:,topk_idx]\n",
    "    v = model.layer1.weight.data[:,topk_idx]\n",
    "    model.layer0.centers.data = c\n",
    "    model.layer1.weight.data = v\n",
    "    model.layer0.bias.data = s\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ImportanceEstimator:\n",
    "    \n",
    "    def __init__(self, module):\n",
    "        self.module = module\n",
    "        self.outputs = None\n",
    "        self.gradients = None\n",
    "        self.back_hook = None\n",
    "        self.forw_hook = None\n",
    "        self.significance = None\n",
    "        self.reset_significance()\n",
    "        \n",
    "    def reset_significance(self):\n",
    "        _N = self.module.centers.shape[0]\n",
    "        if self.module.epsilon is not None:\n",
    "            _N += 1\n",
    "        self.significance = torch.zeros(_N)\n",
    "        \n",
    "    def accumulate_significance(self):\n",
    "        with torch.no_grad():\n",
    "            self.significance += torch.sum((self.outputs*self.gradients)**2, dim=0)\n",
    "        \n",
    "    def capture_outputs(self, module, inp, out):\n",
    "        self.outputs = out.data.cpu()\n",
    "\n",
    "    def capture_gradients(self, module, gradi, grado):\n",
    "        self.gradients = grado[0].data.cpu()\n",
    "        \n",
    "    def attach_hook(self):\n",
    "        self.forw_hook = self.module.softmax.register_forward_hook(self.capture_outputs)\n",
    "        self.back_hook = self.module.softmax.register_backward_hook(self.capture_gradients)\n",
    "        \n",
    "    def remove_hook(self):\n",
    "        self.back_hook.remove()\n",
    "        self.forw_hook.remove()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def none_grad(model):\n",
    "    for p in model.parameters():\n",
    "        p.grad = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imp_est = ImportanceEstimator(residual0.layer0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mse_loss = nn.MSELoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "none_grad(residual0)\n",
    "\n",
    "imp_est.attach_hook()\n",
    "h1 = residual0(xx)\n",
    "h1.register_hook(lambda grad: grad/torch.norm(grad, dim=1, keepdim=True))\n",
    "####################################\n",
    "#         grad = torch.randn_like(yout)\n",
    "#         yout.backward(gradient=grad)\n",
    "###################################\n",
    "mse_loss(h1, tt_0).backward()\n",
    "imp_est.accumulate_significance()\n",
    "\n",
    "imp_est.remove_hook()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imp_est.significance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove_neurons_from_residual(residual0, imp_est.significance, N_search0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    h1 = residual0(xx)\n",
    "    yout = classifier(h1)\n",
    "accuracy = (yout.max(dim=1)[1] == yy).type(torch.float).mean()\n",
    "accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(yout.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    h1 = residual0(xx)\n",
    "    yout = classifier(h1)\n",
    "accuracy = (yout.max(dim=1)[1] == yy).type(torch.float).mean()\n",
    "accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accs_tup = [[accuracy, \"init\"]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Optimize Iteratively"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "STEPS = 200\n",
    "for step in range(STEPS):\n",
    "    ## Add\n",
    "    randidx = torch.randperm(len(xx))[:N_search0]\n",
    "    shift_by = tt_0[randidx] - xx[randidx] - residual0.layer1.bias.data\n",
    "    add_neurons_to_residual(residual0, xx[randidx], shift_by)\n",
    "    with torch.no_grad():\n",
    "        h1 = residual0(xx)\n",
    "        yout = classifier(h1)\n",
    "    accuracy_add = (yout.max(dim=1)[1] == yy).type(torch.float).mean()\n",
    "    \n",
    "    accs_tup += [[accuracy_add, \"add\"]]    \n",
    "    \n",
    "    ## Prune\n",
    "    none_grad(residual0)\n",
    "    imp_est.reset_significance()\n",
    "    imp_est.attach_hook()\n",
    "    \n",
    "    h1 = residual0(xx)\n",
    "#     h1.register_hook(lambda grad: grad/torch.norm(grad, dim=1, keepdim=True))\n",
    "    ####################################\n",
    "#     grad = torch.randn_like(h1)\n",
    "#     h1.backward(gradient=grad)\n",
    "    ###################################\n",
    "    mse_loss(h1, tt_0).backward()\n",
    "#     log_nll_loss(classifier(h1), yy).backward()\n",
    "\n",
    "    ###################################\n",
    "    imp_est.accumulate_significance()\n",
    "    imp_est.remove_hook()\n",
    "    \n",
    "    remove_neurons_from_residual(residual0, imp_est.significance, N_search0)\n",
    "    with torch.no_grad():\n",
    "        h1 = residual0(xx)\n",
    "        yout = classifier(h1)\n",
    "        loss = criterion(yout, yy)\n",
    "    accuracy_prune = (yout.max(dim=1)[1] == yy).type(torch.float).mean()\n",
    "    \n",
    "    accs_tup += [[accuracy_prune, \"prune\"]]    \n",
    "    \n",
    "    \n",
    "    print(f'Step:{step}, AccAdd:{float(accuracy_add):.2f}, Acc:{float(accuracy_prune):.2f}, Loss:{float(loss):.3f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imp_est.significance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualize Neurons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "h1 = residual0(xx)\n",
    "yout = classifier(h1)\n",
    "out = yout.max(dim=1)[1].data.cpu().numpy()\n",
    "## centroids and shift\n",
    "c = residual0.layer0.centers.data.cpu()\n",
    "d = residual0.layer1.weight.data.cpu().t() #+ .cpu()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy = (yout.max(dim=1)[1] == yy).type(torch.float).mean()\n",
    "accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_actv = residual0.layer0(residual0.layer0.centers.data).data.cpu()\n",
    "max_actv = max_actv.diag()#.numpy()\n",
    "max_actv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = plt.figure(figsize=(6,5)).add_subplot()\n",
    "ax.scatter(h1.data[:,0], h1.data[:,1], c=yy, marker= '.', alpha=0.3)\n",
    "\n",
    "ax.scatter(x1, x2, c=out, marker= '.', alpha=0.3, cmap=\"coolwarm\")\n",
    "\n",
    "for i in range(c.shape[0]):\n",
    "    color = matplotlib.cm.tab10(i%20)\n",
    "    ax.arrow(c[i,0], c[i,1], d[i,0], d[i,1], head_width=0.15, head_length=0.1, fc=color, ec=color, linestyle=(0, (5, 10)))\n",
    "    ax.scatter(c[i,0], c[i,1], color=color, marker= 'x')\n",
    "    \n",
    "color = \"k\"\n",
    "ax.arrow(0, 0, d[len(c),0], d[len(c),1], head_width=0.15, head_length=0.1, fc=\"k\", ec=\"k\", linestyle=(0, (5, 10)), linewidth=2.0)\n",
    "    \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "residual0.layer0.bias.data, residual0.layer0.scaler, torch.exp(residual0.layer0.scaler)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Visualize residual-layer neuron's activation region"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "residual0(XX)\n",
    "YY = residual0.layer0.temp_activ\n",
    "YY = YY.reshape(num_points, num_points, -1)\n",
    "YY.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_actv = residual0.layer0(residual0.layer0.centers.data).data.cpu().diag()\n",
    "max_actv_ = max_actv.numpy()\n",
    "max_actv_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for idx in range(YY.shape[-1]):\n",
    "    conf = YY[:,:,idx]\n",
    "    conf = conf.data.cpu().numpy().reshape(X1.shape)\n",
    "    \n",
    "    ax = plt.figure(figsize=(6,6)).add_subplot()\n",
    "    ax.scatter(x1, x2, c=out, marker= '.', alpha=0.3)\n",
    "\n",
    "    ## plot centroids\n",
    "    for i in range(c.shape[0]):\n",
    "        color = matplotlib.cm.tab20(i%20)\n",
    "        ax.scatter(c[i,0], c[i,1], color=color, marker= 'x', s=100)\n",
    "    \n",
    "    try:\n",
    "        ax.scatter(c[idx,0], c[idx,1], color=\"k\", marker= 'X', s=100)\n",
    "        print(f\"center:\",max_actv_[idx],\"max_grid:\",conf.max(), max_actv_[idx] >= conf.max())\n",
    "    except:\n",
    "        pass\n",
    "    \n",
    "    maxpt = XX[conf.argmax()]\n",
    "    ax.scatter(maxpt[0], maxpt[1], color=\"r\", marker= 'o', s=100)\n",
    "    \n",
    "    plt.imshow(conf, interpolation='nearest',\n",
    "           extent=(X1.min(), X1.max(), X2.min(), X2.max()),\n",
    "           alpha=0.6, cmap='gray',\n",
    "           aspect='auto', origin='lower')\n",
    "    \n",
    "    LVLs = 20\n",
    "#     LVLs = torch.linspace(0.0, 0.99, 20)\n",
    "    cs = ax.contour(X1, X2, conf, levels=LVLs, linestyles=\"None\", colors=\"k\", linewidths=1, zorder=-2)\n",
    "    ax.clabel(cs, cs.levels, inline=True, fontsize=8, fmt=\"%1.2f\")\n",
    "    \n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "residual0.layer0.scaler, torch.exp(residual0.layer0.scaler), residual0.layer0.bias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "residual0.layer0.scale_shift.scaler, residual0.layer0.epsilon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# residual0.layer0.epsilon = 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# residual0.layer0.scaler.data[0,0] = 3.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# residual0.layer0.scale_shift.scaler = 5.0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train 2layer LocalMLP with noisy method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "H0 = 20\n",
    "N_search0 = 1\n",
    "\n",
    "model = LocalMLP_DTeSM(2, H0, 2, epsilon=0.4, itemp=7.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.layer0.scaler.data[0,0] = 2.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.layer1.weight.data[:, -1] = model.layer1.weight.data[:, -1]*0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## random init\n",
    "randidx = torch.randperm(len(xx))[:H0]\n",
    "model.layer0.centers.data = xx[randidx] \n",
    "yy_0 = yy[randidx]\n",
    "tt_0 = torch.zeros(H0, 2)\n",
    "for i in range(len(tt_0)):\n",
    "    tt_0[i, yy_0[i]] = 1.\n",
    "model.layer1.weight.data[:, :H0] = tt_0.t()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "randidx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model(xx).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    yout = model(xx)\n",
    "accuracy = (yout.max(dim=1)[1] == yy).type(torch.float).mean()\n",
    "accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accs_tup2 = [[accuracy, \"init\"]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualize mlp layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model(XX)\n",
    "YY = model.layer0.temp_activ\n",
    "YY = YY.reshape(num_points, num_points, -1)\n",
    "YY.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "out = yout.max(dim=1)[1].data.cpu().numpy()\n",
    "## centroids and shift\n",
    "c = model.layer0.centers.data.cpu()\n",
    "# d = model.layer1.weight.data.cpu().t() #+ .cpu()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_actv = model.layer0(model.layer0.centers.data).data.cpu().diag()\n",
    "max_actv_ = max_actv.numpy()\n",
    "max_actv_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for idx in range(YY.shape[-1]):\n",
    "    conf = YY[:,:,idx]\n",
    "    conf = conf.data.cpu().numpy().reshape(X1.shape)\n",
    "    \n",
    "    ax = plt.figure(figsize=(6,6)).add_subplot()\n",
    "    ax.scatter(x1, x2, c=out, marker= '.', alpha=0.3)\n",
    "\n",
    "    ## plot centroids\n",
    "    for i in range(c.shape[0]):\n",
    "        color = matplotlib.cm.tab20(i%20)\n",
    "        ax.scatter(c[i,0], c[i,1], color=color, marker= 'x', s=100)\n",
    "    \n",
    "    try:\n",
    "        ax.scatter(c[idx,0], c[idx,1], color=\"k\", marker= 'X', s=100)\n",
    "        print(f\"center:\",max_actv_[idx],\"max_grid:\",conf.max(), max_actv_[idx] >= conf.max())\n",
    "    except:\n",
    "        pass\n",
    "    \n",
    "    maxpt = XX[conf.argmax()]\n",
    "    ax.scatter(maxpt[0], maxpt[1], color=\"r\", marker= 'o', s=100)\n",
    "    \n",
    "    plt.imshow(conf, interpolation='nearest',\n",
    "           extent=(X1.min(), X1.max(), X2.min(), X2.max()),\n",
    "           alpha=0.6, cmap='gray',\n",
    "           aspect='auto', origin='lower')\n",
    "    \n",
    "    LVLs = 20\n",
    "#     LVLs = torch.linspace(0.0, 0.99, 20)\n",
    "    cs = ax.contour(X1, X2, conf, levels=LVLs, linestyles=\"None\", colors=\"k\", linewidths=1, zorder=-2)\n",
    "    ax.clabel(cs, cs.levels, inline=True, fontsize=8, fmt=\"%1.2f\")\n",
    "    \n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Add and Prune"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imp_est = ImportanceEstimator(model.layer0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "STEPS = 200\n",
    "for step in range(STEPS):\n",
    "    ## Add\n",
    "    randidx = torch.randperm(len(xx))[:N_search0]\n",
    "    yy_0 = yy[randidx]\n",
    "    tt_0 = torch.zeros(len(yy_0), 2)\n",
    "    for i in range(len(yy_0)):\n",
    "        tt_0[i, yy_0[i]] = 1.\n",
    "    add_neurons_to_residual(model, xx[randidx], tt_0)\n",
    "    with torch.no_grad():\n",
    "        yout = model(xx)\n",
    "    accuracy_add = (yout.max(dim=1)[1] == yy).type(torch.float).mean()\n",
    "    \n",
    "    accs_tup2 += [[accuracy_add, \"add\"]]    \n",
    "    \n",
    "    ## Prune\n",
    "    none_grad(model)\n",
    "    imp_est.reset_significance()\n",
    "    imp_est.attach_hook()\n",
    "    \n",
    "    yout = model(xx)\n",
    "#     yout.register_hook(lambda grad: grad/torch.norm(grad, dim=1, keepdim=True))\n",
    "    ####################################\n",
    "#     grad = torch.randn_like(yout)\n",
    "#     yout.backward(gradient=grad)\n",
    "    ###################################\n",
    "    criterion(yout, yy).backward()\n",
    "    ###################################\n",
    "    imp_est.accumulate_significance()\n",
    "    imp_est.remove_hook()\n",
    "    \n",
    "    remove_neurons_from_residual(model, imp_est.significance, N_search0)\n",
    "    with torch.no_grad():\n",
    "        yout = model(xx)\n",
    "        loss = criterion(yout, yy)\n",
    "    accuracy_prune = (yout.max(dim=1)[1] == yy).type(torch.float).mean()\n",
    "    accs_tup2 += [[accuracy_prune, \"prune\"]]    \n",
    "\n",
    "    print(f'Step:{step}, AccAdd:{float(accuracy_add):.2f}, Acc:{float(accuracy_prune):.2f}, Loss:{float(loss):.3f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imp_est.significance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Display Adversarial Examples on 2D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## take some random input as sample\n",
    "ridx = torch.randperm(len(xx))[:9]\n",
    "txx = xx[ridx]\n",
    "txx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "txx = torch.autograd.Variable(txx, requires_grad=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tyy = yy[ridx]\n",
    "tyy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.zero_grad()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss = criterion(model(txx), 1-tyy)\n",
    "loss.backward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "txx.grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_points = 1000\n",
    "X1 = np.linspace(-1.5, 1.5, num_points)\n",
    "X2 = np.linspace(-1.5, 1.5, num_points)\n",
    "X1, X2 = np.meshgrid(X1, X2)\n",
    "\n",
    "XX = torch.Tensor(np.c_[X1.reshape(-1), X2.reshape(-1)]).to(device)\n",
    "XX.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# oYY =model(XX).argmax(dim=-1).reshape(num_points, num_points)\n",
    "\n",
    "oYY =torch.nn.functional.softmax(model(XX), dim=-1)\n",
    "oYY = oYY@torch.Tensor([0, 1])\n",
    "oYY = oYY.reshape(num_points, num_points)\n",
    "\n",
    "YY = model.layer0.temp_activ\n",
    "YY = YY.reshape(num_points, num_points, -1)\n",
    "YY.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "oYY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "out = yout.max(dim=1)[1].data.cpu().numpy()\n",
    "## centroids and shift\n",
    "c = model.layer0.centers.data.cpu()\n",
    "# d = model.layer1.weight.data.cpu().t() #+ .cpu()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_actv = model.layer0(model.layer0.centers.data).data.cpu().diag()\n",
    "max_actv_ = max_actv.numpy()\n",
    "max_actv_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx = model.layer0.num_centers\n",
    "conf = YY[:,:,idx]\n",
    "conf = conf.data.cpu().numpy().reshape(X1.shape)\n",
    "\n",
    "ax = plt.figure(figsize=(6,6)).add_subplot()\n",
    "ax.scatter(x1, x2, c=out, marker= '.', ec='k',alpha=0.3)\n",
    "\n",
    "## plot centroids\n",
    "for i in range(c.shape[0]):\n",
    "    color = matplotlib.cm.tab20(i%20)\n",
    "    ax.scatter(c[i,0], c[i,1], color=color, marker= 'x', s=100)\n",
    "\n",
    "try:\n",
    "    ax.scatter(c[idx,0], c[idx,1], color=\"k\", marker= 'X', s=100)\n",
    "    print(f\"center:\",max_actv_[idx],\"max_grid:\",conf.max(), max_actv_[idx] >= conf.max())\n",
    "except:\n",
    "    pass\n",
    "\n",
    "ax.imshow(oYY.data.numpy(), interpolation='nearest',\n",
    "       extent=(X1.min(), X1.max(), X2.min(), X2.max()),\n",
    "       alpha=0.3,\n",
    "       aspect='auto', origin='lower')\n",
    "\n",
    "# LVLs = 10\n",
    "LVLs = torch.linspace(0.0, 1.0, 10)**2\n",
    "cs = ax.contour(X1, X2, conf, levels=LVLs, linestyles=\"None\", colors=\"k\", linewidths=1, zorder=-2)\n",
    "ax.clabel(cs, cs.levels, inline=True, fontsize=8, fmt=\"%1.2f\")\n",
    "\n",
    "_c = txx.data.numpy()\n",
    "ax.scatter(_c[:,0], _c[:,1], facecolor=\"w\", edgecolor=\"r\", marker= 'o', s=100)\n",
    "_d = -txx.grad.data.numpy()\n",
    "_d = _d/np.linalg.norm(_d, axis=-1, keepdims=True)*0.3\n",
    "for i in range(len(_d)):\n",
    "    ax.arrow(_c[i,0], _c[i,1], _d[i,0], _d[i,1], head_width=0.1, head_length=0.1, fc=\"r\", ec=\"r\", linestyle=\"solid\")\n",
    "\n",
    "plt.savefig(\"outputs/adversarial-2d-demo.pdf\", bbox_inches=\"tight\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('outputs/18_epsHighway_accs_noisy.pkl', 'rb') as handle:\n",
    "    accs_tup3 = pickle.load(handle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(accs_tup), len(accs_tup2), len(accs_tup3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,4))\n",
    "\n",
    "data_res = np.array([(i, acc) for i, (acc, _) in enumerate(accs_tup)])\n",
    "plt.plot(data_res[:,0], data_res[:,1], marker='.', linestyle='dotted', color='tab:orange', label=r\"$\\epsilon$-residual\")\n",
    "\n",
    "data_mlp = np.array([(i, acc) for i, (acc, _) in enumerate(accs_tup2)])\n",
    "plt.plot(data_mlp[:,0], data_mlp[:,1], marker='.', linestyle='dotted', color='tab:green', label=r\"$\\epsilon$-mlp\")\n",
    "\n",
    "data_hig = np.array([(i, acc) for i, (acc, _) in enumerate(accs_tup3)])\n",
    "plt.plot(data_hig[:,0], data_hig[:,1], marker='.', linestyle='dotted', color='tab:blue', label=r\"$\\epsilon$-highway\")\n",
    "\n",
    "plt.legend()\n",
    "plt.xlabel(\"noisy search steps\")\n",
    "plt.ylabel(\"accuracy\")\n",
    "plt.savefig(\"outputs/2d_toy_noisy_search.pdf\", bbox_inches=\"tight\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
