{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43fb4dc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import copy\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.mplot3d import Axes3D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f942dfe8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import dtnnlib as dtnn\n",
    "import resnet_cifar\n",
    "\n",
    "from torchvision import datasets, transforms as T\n",
    "from torch.utils import data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecadd24a",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.set_float32_matmul_precision('high')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67efd8ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "import os, time, sys, random, json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6f431fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "cifar_train = T.Compose([\n",
    "    T.RandomCrop(size=32, padding=4),\n",
    "    T.RandomHorizontalFlip(),\n",
    "    T.ToTensor(),\n",
    "    T.Normalize(\n",
    "        mean=[0.4914, 0.4822, 0.4465], # mean=[0.5071, 0.4865, 0.4409] for cifar100\n",
    "        std=[0.2023, 0.1994, 0.2010], # std=[0.2009, 0.1984, 0.2023] for cifar100\n",
    "    ),\n",
    "])\n",
    "\n",
    "cifar_test = T.Compose([\n",
    "    T.ToTensor(),\n",
    "    T.Normalize(\n",
    "        mean=[0.4914, 0.4822, 0.4465], # mean=[0.5071, 0.4865, 0.4409] for cifar100\n",
    "        std=[0.2023, 0.1994, 0.2010], # std=[0.2009, 0.1984, 0.2023] for cifar100\n",
    "    ),\n",
    "])\n",
    "\n",
    "train_dataset = datasets.CIFAR10(root=\"data/\", train=True, download=True, transform=cifar_train)\n",
    "test_dataset = datasets.CIFAR10(root=\"data/\", train=False, download=True, transform=cifar_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e2cbfd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 64\n",
    "train_loader = data.DataLoader(dataset=train_dataset, num_workers=4, batch_size=batch_size, shuffle=True)\n",
    "test_loader = data.DataLoader(dataset=test_dataset, num_workers=4, batch_size=batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c31a5709",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda:0\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c68635f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5383efb",
   "metadata": {},
   "outputs": [],
   "source": [
    "for xx, yy in train_loader:\n",
    "    xx, yy = xx.to(device), yy.to(device)\n",
    "    print(xx.shape, yy.shape)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89c95e85",
   "metadata": {},
   "outputs": [],
   "source": [
    "net = resnet_cifar.cifar_resnet20(num_classes=10, distance=2)\n",
    "net.conv1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd428ec7",
   "metadata": {},
   "source": [
    "## Try Different metrics for CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c6f1caf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(epoch, model, optimizer):\n",
    "    model.train()\n",
    "    train_loss = 0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    for batch_idx, (inputs, targets) in enumerate(train_loader):\n",
    "        inputs, targets = inputs.to(device), targets.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, targets)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        train_loss += loss.item()\n",
    "        _, predicted = outputs.max(1)\n",
    "        total += targets.size(0)\n",
    "        correct += predicted.eq(targets).sum().item()\n",
    "    return train_loss/(batch_idx+1), correct/total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "595490f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(epoch, model, model_name):\n",
    "    model.eval()\n",
    "    test_loss = 0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        for batch_idx, (inputs, targets) in enumerate(test_loader):\n",
    "            inputs, targets = inputs.to(device), targets.to(device)\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, targets)\n",
    "\n",
    "            test_loss += loss.item()\n",
    "            _, predicted = outputs.max(1)\n",
    "            total += targets.size(0)\n",
    "            correct += predicted.eq(targets).sum().item()\n",
    "            \n",
    "    return test_loss/(batch_idx+1), correct/total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "470c07e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "EPOCHS = 200\n",
    "# EPOCHS = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "030ba3d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    with open(f\"./outputs/04_bench_metrics_c10_res20.json\") as f:\n",
    "        accs_bench = json.load(f)\n",
    "except:\n",
    "    accs_bench = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9e452fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "accs_bench"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59cc699a",
   "metadata": {},
   "outputs": [],
   "source": [
    "SEEDS = [852, 963, 159, 147]\n",
    "for seed in SEEDS:\n",
    "    acc_dict = {}\n",
    "    for key in [\"stereographic\", \"linear\", 2]:\n",
    "        _s = str(seed)\n",
    "        _k = str(key)\n",
    "        if str(_s) in accs_bench.keys():\n",
    "            if str(_k) in accs_bench[str(_s)].keys():\n",
    "                if len(accs_bench[_s][_k][\"test_acc\"]) == EPOCHS:\n",
    "                    print(f\"Completed for {_k}; seed {_s}\")\n",
    "                    continue\n",
    "        \n",
    "        print(\"_________________________\")\n",
    "        print(f\"Experimenting for {key}; seed {seed}\")\n",
    "        \n",
    "        torch.manual_seed(seed)\n",
    "        np.random.seed(seed)\n",
    "        random.seed(seed)\n",
    "        train_loader = data.DataLoader(dataset=train_dataset, num_workers=4, batch_size=batch_size, shuffle=True)\n",
    "        test_loader = data.DataLoader(dataset=test_dataset, num_workers=4, batch_size=batch_size, shuffle=False)\n",
    "        \n",
    "        net = resnet_cifar.cifar_resnet20(num_classes=10, distance=key).to(device)\n",
    "        net = torch.compile(net)\n",
    "\n",
    "        model_name = f\"04_c10_{str(key)}_s{seed}\"\n",
    "\n",
    "        criterion = nn.CrossEntropyLoss()\n",
    "        optimizer = torch.optim.SGD(net.parameters(), lr=0.1,\n",
    "                              momentum=0.9, weight_decay=5e-4)\n",
    "        scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=EPOCHS)\n",
    "        best_acc = -1\n",
    "        \n",
    "        train_losses, train_accs = [], []\n",
    "        test_losses, test_accs = [], []\n",
    "        for epoch in tqdm(range(EPOCHS)):\n",
    "            tr_loss, tr_acc = train(epoch, net, optimizer)\n",
    "            train_losses.append(tr_loss)\n",
    "            train_accs.append(tr_acc)\n",
    "            te_loss, te_acc = test(epoch, net, model_name)\n",
    "            test_losses.append(te_loss)\n",
    "            test_accs.append(te_acc)\n",
    "            \n",
    "            ######## Save checkpoint.\n",
    "            if te_acc > best_acc:\n",
    "                state = {\n",
    "                    'model': net.state_dict(),\n",
    "                    'acc': te_acc,\n",
    "                    'epoch': epoch,\n",
    "                }\n",
    "                if not os.path.isdir('models'): os.mkdir('models')\n",
    "                torch.save(state, f'./models/{model_name}.pth')\n",
    "                best_acc = te_acc\n",
    "            #######################\n",
    "            \n",
    "            scheduler.step()\n",
    "        ##### after full training\n",
    "        acc_dict[key] = {\"train_acc\":train_accs, \"train_loss\":train_losses, \"test_acc\":test_accs, \"test_loss\":test_losses}\n",
    "        accs_bench[seed] = acc_dict\n",
    "        ## Save it in the file.\n",
    "        with open(f\"./outputs/04_bench_metrics_c10_res20.json\", \"w\") as f:\n",
    "            json.dump(accs_bench, f, indent=3)\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3899c091",
   "metadata": {},
   "outputs": [],
   "source": [
    "accs_bench"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69066ecc",
   "metadata": {},
   "source": [
    "## Plot the training curves"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb29a32f",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(f\"./outputs/04_bench_metrics_c10_res20.json\") as f:\n",
    "    benchmark = json.load(f, object_pairs_hook=array_on_duplicate_keys)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95c576a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "for seed in benchmark.keys():\n",
    "    print(seed, benchmark[seed].keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ca546dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_accs_per_seed = {}\n",
    "for m in [\"stereographic\", \"linear\", \"2\"]:\n",
    "    maxk, maxv = None, -1\n",
    "    print(m)\n",
    "    for seed in benchmark.keys():\n",
    "        max_test_acc = np.max(benchmark[seed][m][\"test_acc\"])\n",
    "        print(seed, max_test_acc)\n",
    "        if max_test_acc > maxv:\n",
    "            maxv = max_test_acc\n",
    "            maxk = seed\n",
    "    all_accs_per_seed[m] = maxk\n",
    "    print(f\"\\t\\t{maxk} : {maxv}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ee44125",
   "metadata": {},
   "outputs": [],
   "source": [
    "# all_accs_per_seed"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b72deabf",
   "metadata": {},
   "source": [
    "### plot for highest accuracies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffb960f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(2, 3, figsize=(12,6))\n",
    "axs[0][0].set_ylabel(\"accuracy\")\n",
    "axs[1][0].set_ylabel(\"loss\")\n",
    "\n",
    "names = {'stereographic': 'istereo', 'linear': 'linear', '2': r'$l^2$'}\n",
    "\n",
    "for i, (m, s) in enumerate(all_accs_per_seed.items()):\n",
    "\n",
    "    data = benchmark[s][m]\n",
    "\n",
    "    axs[0][i].plot(data[\"train_acc\"], label=\"train\", color='tab:red')\n",
    "    axs[0][i].plot(data[\"test_acc\"], label=\"test\", color='tab:green')\n",
    "    axs[0][i].set_xticks([])\n",
    "    axs[0][i].legend()    \n",
    "\n",
    "    axs[1][i].plot(data[\"train_loss\"], label=\"train\", color='tab:pink')\n",
    "    axs[1][i].plot(data[\"test_loss\"], label=\"test\", color='tab:blue')\n",
    "    axs[1][i].set_xlabel(r\"epochs $\\to$ \"+names[m])\n",
    "    axs[1][i].legend()    \n",
    "    \n",
    "plt.savefig(\"./outputs/04_bench_metrics_c10_res20_best_plot.pdf\", bbox_inches=\"tight\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3ac401a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
