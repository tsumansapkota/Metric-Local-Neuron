{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import copy\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "import matplotlib\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import dtnnlib as dtnn\n",
    "\n",
    "%matplotlib inline\n",
    "matplotlib.rcParams['figure.figsize'] = (9, 8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# device = torch.device(\"cuda:0\")\n",
    "device = torch.device(\"cpu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Building 2D model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def twospirals(n_points, noise=.5, angle=784):\n",
    "    \"\"\"\n",
    "     Returns the two spirals dataset.\n",
    "    \"\"\"\n",
    "    n = np.sqrt(np.random.rand(n_points,1)) * angle * (2*np.pi)/360\n",
    "    d1x = -np.cos(n)*n + np.random.rand(n_points,1) * noise\n",
    "    d1y = np.sin(n)*n + np.random.rand(n_points,1) * noise\n",
    "    return (np.vstack((np.hstack((d1x,d1y)),np.hstack((-d1x,-d1y)))), \n",
    "            np.hstack((np.zeros(n_points),np.ones(n_points))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(1)\n",
    "x, y = twospirals(300, angle=560)\n",
    "x, y = x/x.max(axis=0, keepdims=True), y.reshape(-1)\n",
    "xx, yy = torch.FloatTensor(x), torch.FloatTensor(y.reshape(-1,1))\n",
    "\n",
    "x1 = xx[:,0]\n",
    "x2 = xx[:,1]\n",
    "\n",
    "%matplotlib inline\n",
    "plt.figure(figsize=(5,5))\n",
    "plt.scatter(x1, x2, c=y, marker='.')\n",
    "plt.xlabel(\"x1\")\n",
    "plt.ylabel(\"x2\")\n",
    "plt.axis(\"equal\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xx, yy = xx.to(device), yy.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Distance Based Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DistanceTransform_Epsilon(dtnn.DistanceTransformBase):\n",
    "    \n",
    "    def __init__(self, input_dim, num_centers, p=2, bias=False, epsilon=0.1, itemp=1):\n",
    "        super().__init__(input_dim, num_centers, p=2)\n",
    "        \n",
    "        nc = num_centers\n",
    "        self.scaler = nn.Parameter(torch.log(torch.ones(1, 1)*itemp))\n",
    "        if epsilon is not None:\n",
    "            nc += 1\n",
    "        self.bias = nn.Parameter(torch.ones(1, nc)*0) if bias else None\n",
    "        self.epsilon = epsilon\n",
    "        \n",
    "    def forward(self, x):\n",
    "        dists = super().forward(x)\n",
    "        \n",
    "        if self.epsilon is not None:\n",
    "            #################################\n",
    "            dists = torch.cat([dists, torch.ones(len(x), 1).to(x)*self.epsilon], dim=1)\n",
    "            #################################\n",
    "        \n",
    "        ## scale the dists (1 is optional)\n",
    "        dists = (1-dists)*torch.exp(self.scaler)\n",
    "    \n",
    "        if self.bias is not None: dists = dists+self.bias\n",
    "        return dists"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## reshape for multi-class classification (including epsilon)\n",
    "yy = yy.reshape(-1).type(torch.LongTensor)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DTeSM Residual "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DTeSM(DistanceTransform_Epsilon):\n",
    "    \n",
    "    def __init__(self, input_dim, output_dim, epsilon=1.0, itemp=10):\n",
    "        ### NOTE: Here, not using bias leads to more uniform centroid activation, and easy to compare..\n",
    "        super().__init__(input_dim, output_dim, bias=False, epsilon=epsilon, itemp=itemp)\n",
    "        \n",
    "        self.scale_shift = dtnn.ScaleShift(-1, scaler_init=1, shifter_init=0, scaler_const=True, shifter_const=True)\n",
    "        self.softmax = nn.Softmax(dim=-1)\n",
    "        self.temp_activ = None\n",
    "        \n",
    "    def forward(self, x):\n",
    "        xo = super().forward(x)\n",
    "        xo = self.scale_shift(xo)\n",
    "        xo = self.softmax(xo)\n",
    "        self.temp_activ = xo.data\n",
    "#         return xo[:, :-1]\n",
    "        return xo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LocalResidual_DTeSM(nn.Module):\n",
    "    \n",
    "    def __init__(self, input_dim, hidden_dim, epsilon=None, itemp=1.0):\n",
    "        super().__init__()\n",
    "        self.layer0 = DTeSM(input_dim, hidden_dim, epsilon, itemp)\n",
    "        if epsilon is not None:\n",
    "            hidden_dim += 1\n",
    "        self.layer1 = nn.Linear(hidden_dim, input_dim)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        h = self.layer0(x)\n",
    "        h = x + self.layer1(h)\n",
    "        return h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(123)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = nn.Sequential(\n",
    "            LocalResidual_DTeSM(2, 10, epsilon=1.0, itemp=10.0),\n",
    "            nn.Linear(2, 2, bias=False)\n",
    "            )\n",
    "\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "criterion = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "yout = model(xx)\n",
    "yout.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "for epoch in range(9000):\n",
    "    yout = model(xx)\n",
    "    \n",
    "    loss = criterion(yout, yy)\n",
    "\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    \n",
    "    model[0].layer1.weight.data[:, -1] = model[0].layer1.weight.data[:, -1]*0 ## zero output epsilon\n",
    "\n",
    "    if (epoch+1)%100 == 0:\n",
    "        yout = model(xx)\n",
    "        accuracy = (yout.max(dim=1)[1] == yy).type(torch.float).mean()                \n",
    "        print(f'Epoch: {epoch}, Acc:{float(accuracy):.2f}, Loss:{float(loss)}')\n",
    "\n",
    "    if (epoch+1)%1000 == 0:\n",
    "        ax = plt.figure(figsize=(6,6)).add_subplot()\n",
    "        out = yout.max(dim=1)[1].data.cpu().numpy()\n",
    "        ax.scatter(x1, x2, c=out, marker= '.')\n",
    "        ## plot centroids\n",
    "        c = model[0].layer0.centers.data.cpu()\n",
    "        ax.scatter(c[:,0], c[:,1], color='k', marker= 'x')\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "h1 = model[0](xx)\n",
    "yout = model[1](h1)\n",
    "out = yout.max(dim=1)[1].data.cpu().numpy()\n",
    "## centroids and shift\n",
    "c = model[0].layer0.centers.data.cpu()\n",
    "d = model[0].layer1.weight.data.cpu().t() #+ net.net[-1].bias.data.cpu()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_actv = model[0].layer0(model[0].layer0.centers.data).data.cpu()\n",
    "max_actv = max_actv.diag()#.numpy()\n",
    "max_actv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! mkdir outputs/14_local_residual/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = plt.figure(figsize=(6,6)).add_subplot()\n",
    "ax.scatter(x1, x2, c=out, marker= '.', alpha=0.3)\n",
    "\n",
    "for i in range(c.shape[0]):\n",
    "    color = matplotlib.cm.tab10(i%20)\n",
    "    ax.arrow(c[i,0], c[i,1], d[i,0], d[i,1], head_width=0.15, head_length=0.1, fc=color, ec=color, linestyle=(0, (5, 10)))\n",
    "    ax.scatter(c[i,0], c[i,1], color=color, marker= 'x')\n",
    "\n",
    "# ax.arrow(0, 0, d[len(c),0], d[len(c),1], head_width=0.15, head_length=0.1, fc=\"k\", ec=\"k\", linestyle=(0, (5, 10)), linewidth=2.0)\n",
    "    \n",
    "plt.xlim(-2.5, 2.5)\n",
    "plt.ylim(-2.5, 2.5)\n",
    "plt.axis(\"equal\")\n",
    "plt.savefig(\"outputs/14_local_residual/local_residual_input.pdf\", bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = plt.figure(figsize=(6,6)).add_subplot()\n",
    "ax.scatter(h1.data[:,0], h1.data[:,1], c=out, marker= '.', alpha=0.3)\n",
    "\n",
    "for i in range(c.shape[0]):\n",
    "    color = matplotlib.cm.tab10(i%20)\n",
    "    ax.arrow(c[i,0], c[i,1], d[i,0], d[i,1], head_width=0.15, head_length=0.1, fc=color, ec=color, linestyle=(0, (5, 10)))\n",
    "    ax.scatter(c[i,0], c[i,1], color=color, marker= 'x')\n",
    "    \n",
    "# color = \"k\"\n",
    "# ax.arrow(0, 0, d[len(c),0], d[len(c),1], head_width=0.15, head_length=0.1, fc=\"k\", ec=\"k\", linestyle=(0, (5, 10)), linewidth=2.0)\n",
    "    \n",
    "plt.xlim(-2.5, 2.5)\n",
    "plt.ylim(-2.5, 2.5)\n",
    "plt.axis(\"equal\")\n",
    "plt.savefig(\"outputs/14_local_residual/local_residual_output.pdf\", bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualize residual neurons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_points = 1000\n",
    "X1 = np.linspace(-2, 2, num_points)\n",
    "X2 = np.linspace(-2, 2, num_points)\n",
    "X1, X2 = np.meshgrid(X1, X2)\n",
    "\n",
    "XX = torch.Tensor(np.c_[X1.reshape(-1), X2.reshape(-1)]).to(device)\n",
    "XX.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model[0](XX)\n",
    "YY = model[0].layer0.temp_activ\n",
    "YY = YY.reshape(num_points, num_points, -1)\n",
    "YY.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dir(model[0].layer0)\n",
    "max_actv = max_actv.numpy()\n",
    "max_actv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for idx in range(YY.shape[-1]):\n",
    "    conf = YY[:,:,idx]\n",
    "    conf = conf.data.cpu().numpy().reshape(X1.shape)\n",
    "    \n",
    "    ax = plt.figure(figsize=(6,6)).add_subplot()\n",
    "    ax.scatter(x1, x2, c=out, marker= '.', alpha=0.3)\n",
    "\n",
    "    ## plot centroids\n",
    "    for i in range(c.shape[0]):\n",
    "        color = matplotlib.cm.tab20(i%20)\n",
    "        ax.scatter(c[i,0], c[i,1], color=color, marker= 'x', s=100)\n",
    "    \n",
    "    try:\n",
    "        ax.scatter(c[idx,0], c[idx,1], color=\"k\", marker= 'X', s=100)\n",
    "        print(f\"center:\",max_actv[idx],\"max_grid:\",conf.max(), max_actv[idx] >= conf.max())\n",
    "    except:\n",
    "        pass\n",
    "    \n",
    "    maxpt = XX[conf.argmax()]\n",
    "    ax.scatter(maxpt[0], maxpt[1], color=\"r\", marker= 'o', s=100)\n",
    "    \n",
    "    plt.imshow(conf, interpolation='nearest',\n",
    "           extent=(X1.min(), X1.max(), X2.min(), X2.max()),\n",
    "           alpha=0.6, cmap='gray',\n",
    "           aspect='auto', origin='lower')\n",
    "    \n",
    "    LVLs = 20\n",
    "#     LVLs = torch.linspace(0.0, 0.99, 20)\n",
    "    cs = ax.contour(X1, X2, conf, levels=LVLs, linestyles=\"None\", colors=\"k\", linewidths=1, zorder=-2)\n",
    "    ax.clabel(cs, cs.levels, inline=True, fontsize=8, fmt=\"%1.2f\")\n",
    "    \n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model[0].layer0.scaler, torch.exp(model[0].layer0.scaler), model[0].layer0.bias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### only for epsilon neuron\n",
    "for idx in [YY.shape[-1]-1]:\n",
    "    conf = YY[:,:,idx]\n",
    "    conf = -torch.log(conf)\n",
    "    \n",
    "    conf = conf.data.cpu().numpy().reshape(X1.shape)\n",
    "    \n",
    "    ax = plt.figure(figsize=(6,6)).add_subplot()\n",
    "    ax.scatter(x1, x2, c=out, marker= '.', alpha=0.3)\n",
    "\n",
    "    ## plot centroids\n",
    "    for i in range(c.shape[0]):\n",
    "        color = matplotlib.cm.tab20(i%20)\n",
    "        ax.scatter(c[i,0], c[i,1], color=color, marker= 'x', s=100)\n",
    "    \n",
    "    try:\n",
    "        ax.scatter(c[idx,0], c[idx,1], color=\"k\", marker= 'X', s=100)\n",
    "        print(f\"center:\",max_actv[idx],\"max_grid:\",conf.max(), max_actv[idx] >= conf.max())\n",
    "    except:\n",
    "        pass\n",
    "    \n",
    "    maxpt = XX[conf.argmax()]\n",
    "    ax.scatter(maxpt[0], maxpt[1], color=\"r\", marker= 'o', s=100)\n",
    "    \n",
    "    plt.imshow(conf, interpolation='nearest',\n",
    "           extent=(X1.min(), X1.max(), X2.min(), X2.max()),\n",
    "           alpha=0.6, cmap='gray',\n",
    "           aspect='auto', origin='lower')\n",
    "    \n",
    "    LVLs = 20\n",
    "#     LVLs = torch.linspace(0.0, 0.99, 20)\n",
    "    cs = ax.contour(X1, X2, conf, levels=LVLs, linestyles=\"None\", colors=\"k\", linewidths=1, zorder=-2)\n",
    "    ax.clabel(cs, cs.levels, inline=True, fontsize=8, fmt=\"%1.2f\")\n",
    "    \n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
