{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils import data\n",
    "\n",
    "from torchvision import transforms as T\n",
    "from torchvision import datasets\n",
    "\n",
    "import random, os, pathlib, time, sys\n",
    "from tqdm import tqdm\n",
    "# from sklearn import datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda:0\")\n",
    "# device = torch.device(\"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# os.environ['CUDA_LAUNCH_BLOCKING'] = '1'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MNIST dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_size = 784\n",
    "output_size = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = datasets.FashionMNIST(root=\"data/\", train=True, download=True)\n",
    "test_dataset = datasets.FashionMNIST(root=\"data/\", train=False, download=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset.data = train_dataset.data.reshape(-1, 784)/255.\n",
    "test_dataset.data = test_dataset.data.reshape(-1, 784)/255."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_dataset.targets = train_dataset.targets.numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_size = 784\n",
    "output_size = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MNIST_Dataset(data.Dataset):\n",
    "    \n",
    "    def __init__(self, data, label):\n",
    "        self.data = data\n",
    "        self.label = label\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "#         print(idx)\n",
    "        img, lbl = self.data[idx], self.label[idx]\n",
    "        return img, lbl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = MNIST_Dataset(train_dataset.data, train_dataset.targets)\n",
    "test_dataset = MNIST_Dataset(test_dataset.data, test_dataset.targets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 50\n",
    "train_loader = data.DataLoader(dataset=train_dataset,\n",
    "                                    num_workers=4, \n",
    "                                    batch_size=batch_size, \n",
    "                                    shuffle=True)\n",
    "\n",
    "test_loader = data.DataLoader(dataset=test_dataset,\n",
    "                                    num_workers=4, \n",
    "                                    batch_size=batch_size, \n",
    "                                    shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Umap pytorch GD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.optimize import curve_fit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class UmapEps(nn.Module):\n",
    "    \n",
    "    def __init__(self, input_dim, output_dim, num_data, num_neighbour,\n",
    "                 min_dist=0.1, spread=1.0, negative_sample_rate=5, num_epsilons=1):\n",
    "        super().__init__()\n",
    "        self.input_dim = input_dim\n",
    "        self.output_dim = output_dim\n",
    "        self.min_dist = min_dist\n",
    "        self.spread = spread\n",
    "        self.num_neighbour = num_neighbour\n",
    "        self.num_data = num_data+num_epsilons\n",
    "        self.num_epsilons = num_epsilons\n",
    "        self.negative_sample_rate = negative_sample_rate\n",
    "        \n",
    "        self.a, self.b = self.find_ab_params(self.spread, self.min_dist)\n",
    "        \n",
    "        self.y_centers = nn.Parameter(torch.randn(self.num_data, self.output_dim)/3.)\n",
    "        self.criterion = nn.BCELoss()\n",
    "        \n",
    "        self.sigma = None\n",
    "        self.cache = None\n",
    "        pass\n",
    "    \n",
    "    def fit_step(self, x, epsilon):\n",
    "        \n",
    "#         neg_num = min(self.negative_sample_rate, x.shape[0]-self.num_neighbour)\n",
    "        neg_num = self.negative_sample_rate*self.num_neighbour\n",
    "\n",
    "        ### can do only once for same x and y .. \n",
    "        if self.cache is None:\n",
    "            assert x.shape[0] > self.num_neighbour\n",
    "            \n",
    "            ### positive sampling only\n",
    "            dists = torch.cdist(x, x)+torch.eye(x.shape[0]).to(x.device)*1e5\n",
    "            \n",
    "            ### add epsilon to all dists\n",
    "            e = torch.ones(x.shape[0], self.num_epsilons).to(x)*epsilon\n",
    "            dists = torch.cat([dists, e], dim=1)\n",
    "\n",
    "            ### add epsilon itself as a node\n",
    "            e = torch.ones(self.num_epsilons, x.shape[0]+self.num_epsilons).to(x)*epsilon\n",
    "            e[:,-self.num_epsilons:] = 0.\n",
    "            \n",
    "            dists = torch.cat([dists, e], dim=0)\n",
    "            \n",
    "            dists, indices = torch.topk(dists, k=self.num_neighbour, dim=1, largest=False, sorted=False)\n",
    "\n",
    "            dists = (dists-dists.min(dim=1, keepdim=True)[0])\n",
    "\n",
    "            if self.sigma is None:\n",
    "                self.sigma = self.get_sigma(dists.data)\n",
    "                self.sigma[torch.isnan(self.sigma)] = 1.\n",
    "\n",
    "            dists = dists/self.sigma\n",
    "            \n",
    "            \n",
    "            dists = torch.exp(-dists)\n",
    "            \n",
    "            \n",
    "            probX = torch.zeros(dists.shape[0], dists.shape[0]).to(x.device)\n",
    "            probX.scatter_(dim=1, index=indices, src=dists)\n",
    "            probX = probX+probX.t()-probX*probX.t()\n",
    "\n",
    "            self.cache = (probX, indices)\n",
    "        else:\n",
    "            probX, indices = self.cache\n",
    "\n",
    "        probX_ = torch.gather(probX, dim=1, index=indices)\n",
    "        dists = torch.cdist(self.y_centers, self.y_centers)\n",
    "        \n",
    "        probY = torch.gather(dists, dim=1, index=indices)\n",
    "        probY = 1/(1+self.a*(probY**(2*self.b)))\n",
    "        loss_positive = self._bceloss_(probX_, probY)\n",
    "\n",
    "#         return loss_positive\n",
    "        \n",
    "        negative_indices = torch.randint(low=0, high=x.shape[0]+self.num_epsilons, size=(x.shape[0]+self.num_epsilons, neg_num)).to(indices.device)\n",
    "        ## by default use this (uses 0 as target)\n",
    "        probX_ = torch.zeros(x.shape[0]+self.num_epsilons, neg_num, device=x.device)\n",
    "        \n",
    "        probY = torch.gather(dists, dim=1, index=negative_indices)\n",
    "        probY = 1/(1+self.a*(probY**(2*self.b)))\n",
    "#         loss_negative = self.criterion(probY, probX_)\n",
    "        loss_negative = self._bceloss_(probX_, probY)\n",
    "        \n",
    "        ### if mean is used\n",
    "        loss = loss_positive+loss_negative*self.negative_sample_rate\n",
    "        ### if sum is used\n",
    "#         loss = (loss_positive+loss_negative)*1/(x.shape[0]*self.num_neighbour)\n",
    "    \n",
    "        return loss\n",
    "    \n",
    "    def get_sigma(self, dists, epoch=700, lr=0.03):\n",
    "        k = dists.shape[1]\n",
    "        sigma = nn.Parameter(torch.std(dists.data, dim=1, keepdim=True)*0.2)\n",
    "        optim = torch.optim.Adam([sigma], lr=lr)\n",
    "        target = torch.log2(torch.ones_like(sigma)*k).to(dists.device)\n",
    "        for i in range(epoch):\n",
    "            delta = torch.sum(torch.exp(-dists/sigma), dim=1, keepdim=True)\n",
    "            delta = delta-target\n",
    "\n",
    "            optim.zero_grad()\n",
    "            error = (delta**2).sum()\n",
    "            error.backward()\n",
    "            optim.step()\n",
    "        return sigma.data\n",
    "    \n",
    "    def _bceloss_(self, pX, pY):\n",
    "        logy = torch.clamp(torch.log(pY), min=-100)\n",
    "        log1_y = torch.clamp(torch.log(1-pY), min=-100)\n",
    "#         logy = torch.log(pY) ## gets nan loss\n",
    "#         log1_y = torch.log(1-pY)\n",
    "        return -torch.mean(pX*logy+(1-pX)*log1_y)\n",
    "    \n",
    "        \n",
    "    def find_ab_params(self, spread, min_dist):\n",
    "\n",
    "        def curve(x, a, b):\n",
    "            return 1.0 / (1.0 + a * x ** (2 * b))\n",
    "\n",
    "        xv = np.linspace(0, spread * 3, 300)\n",
    "        yv = np.zeros(xv.shape)\n",
    "        yv[xv < min_dist] = 1.0\n",
    "        yv[xv >= min_dist] = np.exp(-(xv[xv >= min_dist] - min_dist) / spread)\n",
    "        params, covar = curve_fit(curve, xv, yv)\n",
    "        return params[0], params[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# torch.randn(784, 784)[torch.eye(784).type(torch.bool)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_train = 5000\n",
    "#### use at least 2 epsilon.. so that the eplisons can attract with each other and repel rest.\n",
    "ump = UmapEps(784, 2, num_data=num_train, num_neighbour=10, negative_sample_rate=2, num_epsilons=10*2).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ump.a, ump.b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "indices = np.random.permutation(len(train_loader.dataset.data))[:num_train]\n",
    "xx, yy = train_loader.dataset[indices]\n",
    "xx = xx.to(device)\n",
    "xx.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cdist(xx, xx).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epsilon = 6\n",
    "ump.fit_step(xx, epsilon=epsilon) ## loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# adasd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = torch.optim.Adam(ump.parameters(), lr=0.25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "yy = torch.cat([yy, torch.Tensor([10]*ump.num_epsilons).to(yy)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "yy.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "EPOCHS = 10000#//2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=EPOCHS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Train with Optimizer\n",
    "\n",
    "train_error = []\n",
    "for epoch in tqdm(list(range(EPOCHS))):\n",
    "    \n",
    "    loss = ump.fit_step(xx, epsilon=epsilon)\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    \n",
    "    ump.y_centers.grad[torch.isnan(ump.y_centers.grad)] = 0\n",
    "    \n",
    "    optimizer.step()\n",
    "    scheduler.step()\n",
    "    stdm = ump.y_centers.data.std()\n",
    "\n",
    "    train_error.append(float(loss))\n",
    "    \n",
    "    if epoch%100 == 0:\n",
    "        print(f'Epoch: {epoch},  Loss:{float(loss)}')\n",
    "        plt.scatter(*ump.y_centers.cpu().data.numpy().T, c=yy, marker='.', cmap=\"tab10\")\n",
    "        plt.scatter(*ump.y_centers.cpu().data.numpy()[-ump.num_epsilons:].T, c='k', marker='*', s=100)\n",
    "        \n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(*ump.y_centers.cpu().data.numpy().T, c=yy, marker='.', cmap=\"tab20\", s=1)\n",
    "plt.colorbar(boundaries=np.arange(11)-0.5).set_ticks(np.arange(10))\n",
    "\n",
    "plt.scatter(*ump.y_centers.cpu().data.numpy()[-ump.num_epsilons:].T, c='k', marker='*', s=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "adasdasd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test data samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "indices = np.random.permutation(len(test_loader.dataset.data))[:100]\n",
    "test_xx, test_yy = test_loader.dataset[indices]\n",
    "test_xx = test_xx.to(device)\n",
    "test_xx.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### random uniform samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "randalpha = 0.0\n",
    "\n",
    "test_xx = test_xx*(1-randalpha)+randalpha*torch.rand(100, 784).to(device)\n",
    "test_xx.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transform_step(self, train_x, x, testy_centers, epsilon, cache=None):\n",
    "    \n",
    "    if cache is None:\n",
    "        ########################################\n",
    "        ### Pre computation step\n",
    "        dists = torch.cdist(x, train_x)\n",
    "\n",
    "        ## disconnection_distance parameter not used\n",
    "        \n",
    "        ### add epsilon to all dists\n",
    "        e = torch.ones(x.shape[0], self.num_epsilons).to(x)*epsilon\n",
    "        dists = torch.cat([dists, e], dim=1)\n",
    "        \n",
    "        dists, indices = torch.topk(dists, k=self.num_neighbour, dim=1, largest=False, sorted=False)            \n",
    "            \n",
    "        dists = (dists-dists.min(dim=1, keepdim=True)[0])\n",
    "\n",
    "        sigma = self.get_sigma(dists)\n",
    "        sigma[torch.isnan(sigma)] = 1\n",
    "        \n",
    "        dists = dists/sigma\n",
    "        dists = torch.exp(-dists)\n",
    "\n",
    "        sz = max(x.shape[0], train_x.shape[0])+self.num_epsilons\n",
    "        probX = torch.zeros(sz, sz).to(x.device)\n",
    "\n",
    "        probX.scatter_(dim=1, index=indices, src=dists)\n",
    "\n",
    "        probX = probX+probX.t()-probX*probX.t()\n",
    "\n",
    "        ### find non-zero rows\n",
    "        return (probX, indices)\n",
    "    \n",
    "    \n",
    "    probX, indices = cache\n",
    "    \n",
    "    ######################################\n",
    "    ### positive sampling step\n",
    "    probX = torch.gather(probX, dim=1, index=indices)\n",
    "\n",
    "    dists = torch.cdist(testy_centers, self.y_centers)\n",
    "    \n",
    "    probY = torch.gather(dists, dim=1, index=indices)\n",
    "    probY = 1/(1+self.a*(probY**(2*self.b)))\n",
    "    \n",
    "    \n",
    "    loss_positive = self._bceloss_(probX, probY)\n",
    "    \n",
    "    #############################################\n",
    "    ### negative sampling\n",
    "    neg_num = self.negative_sample_rate*self.num_neighbour\n",
    "    \n",
    "    probX = torch.zeros(x.shape[0], neg_num, device=x.device)\n",
    "    negative_indices = torch.randint(low=0, high=train_x.shape[0]+self.num_epsilons, size=(x.shape[0], neg_num)).to(x.device)\n",
    "    \n",
    "    probY = torch.gather(dists, dim=1, index=negative_indices)\n",
    "    probY = 1/(1+self.a*(probY**(2*self.b)))\n",
    "    loss_negative = self._bceloss_(probX, probY)\n",
    "\n",
    "    ### if mean is used\n",
    "    loss = loss_positive+loss_negative*self.negative_sample_rate\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_centers = nn.Parameter(torch.randn(test_xx.shape[0], ump.output_dim).to(device)/3.)\n",
    "y_centers.requires_grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ## Initialize y_centers with nearest sample from training set\n",
    "# nearest_idx = torch.cdist(test_xx, xx).argmax(dim=1)\n",
    "# y_centers.data = ump.y_centers.data[nearest_idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cache = transform_step(ump, xx, test_xx, y_centers, epsilon, cache=None) ## first get cache\n",
    "# cache"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform_step(ump, xx, test_xx, y_centers, epsilon, cache)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "EPOCHS = 3000\n",
    "optimizer = torch.optim.Adam([y_centers], lr=0.25)\n",
    "scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=EPOCHS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Train with Optimizer\n",
    "\n",
    "train_error = []\n",
    "for epoch in tqdm(list(range(EPOCHS))):\n",
    "    loss = transform_step(ump, xx, test_xx, y_centers, epsilon, cache)\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    \n",
    "#     print(ump.y_centers.grad)\n",
    "#     print(torch.count_nonzero(torch.isnan(ump.y_centers.grad)))\n",
    "#     print(torch.count_nonzero(torch.isinf(ump.y_centers.grad)))\n",
    "    y_centers.grad[torch.isnan(y_centers.grad)] = 0\n",
    "    \n",
    "    optimizer.step()\n",
    "#     stdm = y_centers.data.std()\n",
    "#     ump.y_centers.data = ump.y_centers.data + \\\n",
    "#                 (torch.rand_like(ump.y_centers.data)-0.5)*0.01*float(stdm)\n",
    "\n",
    "    train_error.append(float(loss))\n",
    "    \n",
    "    if epoch%100 == 0:\n",
    "#         print(ump.y_centers.data.std())\n",
    "        print(f'Epoch: {epoch},  Loss:{float(loss)}')\n",
    "        plt.scatter(*y_centers.cpu().data.numpy().T, c=test_yy, marker='.', cmap=\"tab10\")\n",
    "        plt.show()\n",
    "#     break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(*ump.y_centers.cpu().data.numpy().T, c=yy, marker='.', cmap=\"tab10\", s=3, alpha=0.2)\n",
    "\n",
    "plt.scatter(*y_centers.cpu().data.numpy().T, c=test_yy, marker='*', edgecolors='k', s=50, cmap='tab10',\n",
    "            alpha=0.5, zorder=100)\n",
    "\n",
    "plt.colorbar(boundaries=np.arange(11)-0.5).set_ticks(np.arange(10))\n",
    "\n",
    "plt.scatter(*ump.y_centers.cpu().data.numpy()[-ump.num_epsilons:].T, marker='o', edgecolors='k', facecolors='None', s=100,\n",
    "            alpha=0.3, zorder=-100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Plot with interpolation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "indices = np.random.permutation(len(test_loader.dataset.data))[:100]\n",
    "_test_xx, test_yy = test_loader.dataset[indices]\n",
    "_test_xx = _test_xx.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "randalphas = np.linspace(0, 1, 11)\n",
    "alp_idx = -1\n",
    "randalphas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "randval = torch.rand(len(test_xx), 784).to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ==>> rerun below code from here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "alp_idx += 1\n",
    "randalpha = randalphas[alp_idx]\n",
    "print(randalpha)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_xx = _test_xx*(1-randalpha)+randalpha*randval\n",
    "test_xx.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_centers = nn.Parameter(torch.randn(test_xx.shape[0], ump.output_dim).to(device)/3.)\n",
    "y_centers.requires_grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cache = transform_step(ump, xx, test_xx, y_centers, epsilon, cache=None) ## first get cache"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform_step(ump, xx, test_xx, y_centers, epsilon, cache)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "EPOCHS = 3000\n",
    "optimizer = torch.optim.Adam([y_centers], lr=0.25)\n",
    "scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=EPOCHS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Train with Optimizer\n",
    "\n",
    "train_error = []\n",
    "for epoch in tqdm(list(range(EPOCHS))):\n",
    "    loss = transform_step(ump, xx, test_xx, y_centers, epsilon, cache)\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    \n",
    "    y_centers.grad[torch.isnan(y_centers.grad)] = 0\n",
    "    \n",
    "    optimizer.step()\n",
    "\n",
    "    train_error.append(float(loss))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!mkdir ./outputs/16_epsilon_umap/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(*ump.y_centers.cpu().data.numpy().T, c=yy, marker='.', cmap=\"tab10\", s=3, alpha=0.2)\n",
    "\n",
    "plt.scatter(*y_centers.cpu().data.numpy().T, c=test_yy, marker='*', edgecolors='k', s=50, cmap='tab10',\n",
    "            alpha=0.5, zorder=100)\n",
    "plt.colorbar(boundaries=np.arange(11)-0.5).set_ticks(np.arange(10))\n",
    "\n",
    "\n",
    "plt.scatter(*ump.y_centers.cpu().data.numpy()[-ump.num_epsilons:].mean(axis=0, keepdims=True).T, marker='o', edgecolors='k', facecolors='None', s=100,\n",
    "            alpha=1.0, lw=2, zorder=-100)\n",
    "\n",
    "plt.savefig(f\"./outputs/16_epsilon_umap/embed_alpha{np.round(randalpha, decimals=1)}.pdf\", bbox_inches=\"tight\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
