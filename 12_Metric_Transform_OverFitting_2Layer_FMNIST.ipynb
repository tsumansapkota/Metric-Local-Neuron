{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2cc0627",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib\n",
    "%matplotlib inline\n",
    "# from mpl_toolkits.mplot3d import Axes3D\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils import data\n",
    "from torchvision import datasets, transforms as T\n",
    "\n",
    "import random, os, pathlib, time\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e58876c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda:0\")\n",
    "# device = torch.device(\"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc2aa2a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "import os, time, sys\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d64ae85",
   "metadata": {},
   "outputs": [],
   "source": [
    "import dtnnlib as dtnn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fa28214",
   "metadata": {},
   "outputs": [],
   "source": [
    "mnist_transform = T.Compose([\n",
    "    T.ToTensor(),\n",
    "    T.Normalize(\n",
    "        mean=[0.5,],\n",
    "        std=[0.5,],\n",
    "    ),\n",
    "])\n",
    "\n",
    "############################\n",
    "#### Choose Dataset Here ###\n",
    "\n",
    "# train_dataset = datasets.FashionMNIST(root=\"data/\", train=True, download=True, transform=mnist_transform)\n",
    "# test_dataset = datasets.FashionMNIST(root=\"data/\", train=False, download=True, transform=mnist_transform)\n",
    "\n",
    "train_dataset = datasets.MNIST(root=\"data/\", train=True, download=True, transform=mnist_transform)\n",
    "test_dataset = datasets.MNIST(root=\"data/\", train=False, download=True, transform=mnist_transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04d3d813",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 50\n",
    "train_loader = data.DataLoader(dataset=train_dataset, num_workers=4, batch_size=batch_size, shuffle=True)\n",
    "test_loader = data.DataLoader(dataset=test_dataset, num_workers=4, batch_size=batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28a3a857",
   "metadata": {},
   "outputs": [],
   "source": [
    "for xx, yy in train_loader:\n",
    "    xx, yy = xx.to(device), yy.to(device)\n",
    "    print(xx.shape, yy.shape)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d75760af",
   "metadata": {},
   "outputs": [],
   "source": [
    "h = 10\n",
    "model = nn.Sequential(\n",
    "            dtnn.DistanceTransform_MinExp(784, h),\n",
    "            nn.LeakyReLU(),\n",
    "            nn.Linear(h, 10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57636299",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e47ad52",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model[0].set_centroid_to_data(train_loader)\n",
    "# model[0].set_centroid_to_data_randomly(train_loader)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00ae71d5",
   "metadata": {},
   "source": [
    "## Randomly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a82bdf5",
   "metadata": {},
   "outputs": [],
   "source": [
    "N = model[0].centers.shape[0]\n",
    "new_center = []\n",
    "new_labels = []\n",
    "count = 0\n",
    "for i, (xx, yy) in enumerate(train_loader):\n",
    "    xx = xx.reshape(-1, model[0].input_dim).to(model[0].centers.device)\n",
    "    if count+xx.shape[0] < N:\n",
    "        new_center.append(xx)\n",
    "        new_labels.append(yy)\n",
    "        count += xx.shape[0]\n",
    "    elif count >= N:\n",
    "        break\n",
    "    else:\n",
    "        new_center.append(xx[:N-count])\n",
    "        new_labels.append(yy[:N-count])\n",
    "        count = N\n",
    "        break\n",
    "        \n",
    "new_center = torch.cat(new_center, dim=0)\n",
    "new_labels = torch.cat(new_labels, dim=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a7b8c14",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_center.shape, new_labels.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fd1919c",
   "metadata": {},
   "source": [
    "## Set\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3883e959",
   "metadata": {},
   "outputs": [],
   "source": [
    "weights = torch.zeros(len(new_labels), 10)\n",
    "for i in range(len(new_labels)):\n",
    "    weights[i, new_labels[i]] = 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17fdd3f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "weights.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df39f81c",
   "metadata": {},
   "outputs": [],
   "source": [
    "model[0].centers.data = new_center.to(model[0].centers.device)\n",
    "model[-1].weight.data = weights.t().to(model[-1].weight.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44f24529",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_acc = -1\n",
    "def test(epoch, model):\n",
    "    global best_acc\n",
    "    model.eval()\n",
    "    test_loss = 0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "#         for batch_idx, (inputs, targets) in enumerate(tqdm(test_loader)):\n",
    "        for batch_idx, (inputs, targets) in enumerate(test_loader):\n",
    "            inputs, targets = inputs.to(device).view(-1, 28*28), targets.to(device)\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, targets)\n",
    "\n",
    "            test_loss += loss.item()\n",
    "            _, predicted = outputs.max(1)\n",
    "            total += targets.size(0)\n",
    "            correct += predicted.eq(targets).sum().item()\n",
    "            \n",
    "    print(f\"[Test] {epoch} Loss: {test_loss/(batch_idx+1):.3f} | Acc: {100.*correct/total:.3f} {correct}/{total}\")\n",
    "    \n",
    "    acc = 100.*correct/total\n",
    "    return acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02356d00",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a1825c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24fafe71",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_acc = test(0, model)\n",
    "test_acc"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b690e9f8",
   "metadata": {},
   "source": [
    "## Benchmark with stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b306b3d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "HIDDEN_UNITS = [10, 50, 200, 1000, 5000, 20000]\n",
    "\n",
    "seed = 2023\n",
    "np.random.seed(seed)\n",
    "SEEDS = np.random.randint(0, high=9999, size=20)\n",
    "SEEDS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4684e675",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_accuracy = {h:[] for h in HIDDEN_UNITS}\n",
    "test_accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28c8903a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_centers_and_labels(data_loader, N):\n",
    "    new_center = []\n",
    "    new_labels = []\n",
    "    count = 0\n",
    "    for i, (xx, yy) in enumerate(data_loader):\n",
    "        xx = xx.reshape(-1, model[0].input_dim).to(model[0].centers.device)\n",
    "        if count+xx.shape[0] < N:\n",
    "            new_center.append(xx)\n",
    "            new_labels.append(yy)\n",
    "            count += xx.shape[0]\n",
    "        elif count >= N:\n",
    "            break\n",
    "        else:\n",
    "            new_center.append(xx[:N-count])\n",
    "            new_labels.append(yy[:N-count])\n",
    "            count = N\n",
    "            break\n",
    "\n",
    "    new_center = torch.cat(new_center, dim=0)\n",
    "    new_labels = torch.cat(new_labels, dim=0)\n",
    "    return new_center, new_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d915984c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "batch_size = 50\n",
    "for h in HIDDEN_UNITS:\n",
    "    print(f\"Experiment for Hidden units: {h}\")\n",
    "    for seed in tqdm(SEEDS):\n",
    "        seed = int(seed)\n",
    "        torch.manual_seed(seed)\n",
    "        np.random.seed(seed)\n",
    "        random.seed(seed)\n",
    "        \n",
    "        train_loader = data.DataLoader(dataset=train_dataset, num_workers=4, batch_size=batch_size, shuffle=True)\n",
    "        test_loader = data.DataLoader(dataset=test_dataset, num_workers=4, batch_size=batch_size, shuffle=False)\n",
    "        \n",
    "        model = nn.Sequential(\n",
    "                    dtnn.DistanceTransform_MinExp(784, h),\n",
    "                    nn.LeakyReLU(),\n",
    "                    nn.Linear(h, 10)).to(device)\n",
    "        \n",
    "        new_center, new_labels = get_centers_and_labels(train_loader, h)\n",
    "        weights = torch.zeros(len(new_labels), 10)\n",
    "        for i in range(len(new_labels)):\n",
    "            weights[i, new_labels[i]] = 1.\n",
    "            \n",
    "        model[0].centers.data = new_center.to(model[0].centers.device)\n",
    "        model[-1].weight.data = weights.t().to(model[-1].weight.data)\n",
    "        model.eval()\n",
    "        \n",
    "        test_acc = test(0, model)\n",
    "        test_accuracy[h].append(test_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfb3325e",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"H \\tMean \\t\\tSTD \\tMAX\")\n",
    "for k, v in test_accuracy.items():\n",
    "#     print(k, v)\n",
    "    print(f\"{k} \\t{np.mean(v):.4f} \\t{np.std(v):.4f} \\t{np.max(v)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd3297f9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
