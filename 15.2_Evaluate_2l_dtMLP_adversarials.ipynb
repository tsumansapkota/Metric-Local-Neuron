{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5263a99",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import copy\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "# from mpl_toolkits.mplot3d import Axes3D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab15e189",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from torchvision import datasets, transforms as T\n",
    "from torch.utils import data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83a571ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "import os, time, sys\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b4143d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import foolbox as fb\n",
    "import foolbox.attacks as fa\n",
    "\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbdb9640",
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.path.append(\"./Input-Invex-Neural-Network/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fac3e89b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import dtnnlib as dtnn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9ee59a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nflib\n",
    "from nflib.flows import SequentialFlow, ActNorm, ActNorm2D, BatchNorm1DFlow, BatchNorm2DFlow\n",
    "import nflib.res_flow as irf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4fd54dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "mnist_transform = T.Compose([\n",
    "    T.ToTensor(),\n",
    "    T.Normalize(\n",
    "        mean=0.5,\n",
    "        std=0.5,\n",
    "    ),\n",
    "])\n",
    "\n",
    "train_dataset = datasets.FashionMNIST(root=\"data/\", train=True, download=True, transform=mnist_transform)\n",
    "test_dataset = datasets.FashionMNIST(root=\"data/\", train=False, download=True, transform=mnist_transform)\n",
    "# train_dataset = datasets.MNIST(root=\"data/\", train=True, download=True, transform=mnist_transform)\n",
    "# test_dataset = datasets.MNIST(root=\"data/\", train=False, download=True, transform=mnist_transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4b78d5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset.data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "800277ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 100\n",
    "train_loader = data.DataLoader(dataset=train_dataset, num_workers=4, batch_size=batch_size, shuffle=True)\n",
    "test_loader = data.DataLoader(dataset=test_dataset, num_workers=4, batch_size=batch_size, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3bad2b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda:0\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ae133e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "for xx, yy in train_loader:\n",
    "    print(xx.shape)\n",
    "#     xx, yy = xx.view(-1,28*28).to(device), yy.to(device)\n",
    "    xx, yy = xx.to(device), yy.to(device)\n",
    "    print(xx.shape, yy.shape)\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c1c0e08",
   "metadata": {},
   "source": [
    "## Train Test method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b7a979b",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_dir = \"outputs/15.0_models\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f797626",
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68bd8415",
   "metadata": {},
   "source": [
    "## Adverserial Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6ee25d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "attack_dict = {\n",
    "    \"FGSM\": fa.FGSM(), ## LinfFastGradientAttack\n",
    "    \"FGM\": fa.FGM(), ## L2FastGradientAttack\n",
    "    \"L2PGD\": fa.L2PGD(steps=20), ## higher steps (>10) better ??_!!\n",
    "    \"LinfPGD\": fa.LinfPGD(steps=20), ## PGD\n",
    "    \"L1AdamPGD\": fa.L1AdamPGD(steps=20, adam_beta1=0.8, adam_beta2=0.95),\n",
    "    \"L2AdamPGD\": fa.L2AdamPGD(steps=20, adam_beta1=0.8, adam_beta2=0.95),\n",
    "    \"LinfAdamPGD\": fa.LinfAdamPGD(steps=20, adam_beta1=0.8, adam_beta2=0.95),\n",
    "    \"L2AdamBasic\": fa.L2AdamBasicIterativeAttack(steps=10), ## default steps\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25bb6b9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "attack_dict.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "107f4216",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_experiment_instance(ax, hidden_units, data_init, center_lr, \n",
    "                             bound=1, temp_scale=1.0, attack_type=\"FGSM\", adv_alpha=0.5):\n",
    "    \n",
    "    init = \"cent\" if data_init else \"rand\"\n",
    "    model_name = f\"dtesm_identity_I{init}_clrs{center_lr}_h{hidden_units}_mean\"\n",
    "    ckpt = torch.load(f\"{model_dir}/{model_name}.pth\")\n",
    "    accuracy = ckpt[\"acc\"]\n",
    "    \n",
    "    observation_dir = f\"outputs/15.1_evaluating_models/{model_name}/\"\n",
    "    if not os.path.exists(f'{observation_dir}/experiments_data.pkl'):\n",
    "        print(observation_dir, \"does not exist\")\n",
    "        raise ValueError(\"Given parameter does not have experiments\")\n",
    "        \n",
    "    center_lr, bound, temp_scale, adv_alpha = float(center_lr), int(bound), float(temp_scale), float(adv_alpha)\n",
    "    \n",
    "    config = f\"{attack_type}_e{adv_alpha}_b{bound}_ts{temp_scale}\"\n",
    "    with open(f'{observation_dir}/experiments_data.pkl', 'rb') as handle:\n",
    "        actv_data_dict = pickle.load(handle)\n",
    "#         print(actv_data_dict.keys())\n",
    "    data = actv_data_dict[config]\n",
    "    \n",
    "    ##### plot after each experiment\n",
    "    test_count = data[0,2]\n",
    "    ax.plot(data[:,0], data[:,1], lw=2, label=\"measure\", marker='.')\n",
    "    ax.plot(data[:,0], data[:,3]/test_count, linestyle=\"dashed\", label=\"failed\")\n",
    "    ax.plot(data[:,0], data[:,4]/test_count, linestyle=\"dotted\", label=\"rejected\")\n",
    "    ax.plot(data[:,0], data[:,5]/test_count, linestyle=\"dotted\", label=\"x_rejected\")\n",
    "\n",
    "\n",
    "    _mn = f\"init:{init} clr:{center_lr} nh:{hidden_units} acc:{accuracy*100:.1f}\"\n",
    "    _cf = f\"{attack_type} \"+r\"$\\alpha$\"+f\":{int(adv_alpha)} b:[{-int(bound)}, {int(bound)}]\"\n",
    "    ax.set_xlabel(r\"$\\epsilon$ for \"+f\"{_cf}\\n{_mn}\")\n",
    "\n",
    "    ax.legend()\n",
    "    \n",
    "    ax.hlines(data[:,1].min(), data[0,0], data[-1,0], linestyle='dashed', lw=0.5, color='k')\n",
    "    ax.hlines(data[-1,1], data[0,0], data[-1,0], linestyle='dotted', lw=0.5, color='b')\n",
    "    \n",
    "    ax.set_ylim(0,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44eb31ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "!mkdir outputs/15.2_observation\n",
    "!mkdir outputs/15.2_observation/measure_comp_bound"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2805dbce",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Verifies that bound increase also increase rejection..\n",
    "\"\"\"\n",
    "## Choose axis to compare\n",
    "for data_init in [True, False]:\n",
    "    print(\"Data Init = \",data_init)\n",
    "    for attack_type in attack_dict.keys():\n",
    "        for lr in [1.0, 0.01]:\n",
    "            for alpha in [1.0, 3.0, 9.0, 20.0]:\n",
    "                hidden_units = 100\n",
    "                init = \"cent\" if data_init else \"rand\"\n",
    "                _mn = f\"I{init}_clr{lr}_h{hidden_units}\"\n",
    "                _cf = f\"{attack_type}_e{alpha}\"\n",
    "                \n",
    "                print(f\"=========alpha:{alpha}=======\")\n",
    "                fig, axs = plt.subplots(1,2, figsize=(8,3))\n",
    "                plot_experiment_instance(axs[0], hidden_units=hidden_units, data_init=data_init, center_lr=lr, \n",
    "                                         bound=1, temp_scale=1.0, attack_type=attack_type, adv_alpha=alpha)\n",
    "                plot_experiment_instance(axs[1], hidden_units=hidden_units, data_init=data_init, center_lr=lr, \n",
    "                                         bound=10, temp_scale=1.0, attack_type=attack_type, adv_alpha=alpha)\n",
    "\n",
    "                plt.savefig(f\"./outputs/15.2_observation/measure_comp_bound/{_mn};{_cf}.pdf\", bbox_inches=\"tight\")\n",
    "                plt.show()    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53b751c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "!mkdir outputs/15.2_observation/measure_comp_init"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd50cba6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Verifies that center init is better for rejection\n",
    "\"\"\"\n",
    "## Choose axis to compare\n",
    "for hidden_units in [100, 500]:\n",
    "    print(f\"Hidden Units: {hidden_units}\")\n",
    "    for center_lr in [1.0, 0.01]:\n",
    "        print(f\"Center LR: {center_lr}\")\n",
    "        for adv_alpha in [1.0, 3.0, 9.0, 20.0]:\n",
    "            for attack_type in attack_dict.keys():\n",
    "                for bounds in [1, 10]:\n",
    "                    init = \"cent\" if data_init else \"rand\"\n",
    "                    _mn = f\"clr{lr}_h{hidden_units}\"\n",
    "                    _cf = f\"{attack_type}_e{adv_alpha}_b{bounds}\"\n",
    "                    \n",
    "                    fig, axs = plt.subplots(1,2, figsize=(8,3))\n",
    "                    plot_experiment_instance(axs[0], hidden_units=hidden_units, data_init=True, center_lr=center_lr, \n",
    "                                             bound=bounds, temp_scale=1.0, attack_type=attack_type, adv_alpha=adv_alpha)\n",
    "                    plot_experiment_instance(axs[1], hidden_units=hidden_units, data_init=False, center_lr=center_lr, \n",
    "                                             bound=bounds, temp_scale=1.0, attack_type=attack_type, adv_alpha=adv_alpha)\n",
    "                    \n",
    "                    plt.savefig(f\"./outputs/15.2_observation/measure_comp_init/{_mn};{_cf}.pdf\", bbox_inches=\"tight\")\n",
    "                    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9aadaf06",
   "metadata": {},
   "outputs": [],
   "source": [
    "!mkdir outputs/15.2_observation/measure_hidden_units"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8295b4f2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Verifies that more hidden units is better for rejection\n",
    "\"\"\"\n",
    "## Choose axis to compare\n",
    "for data_init in [True, False]:\n",
    "    print(f\"Hidden Units: {hidden_units}\")\n",
    "    for center_lr in [1.0, 0.01]:\n",
    "        print(f\"Center LR: {center_lr}\")\n",
    "        for adv_alpha in [1.0, 3.0, 9.0, 20.0]:\n",
    "            for attack_type in attack_dict.keys():\n",
    "                for bounds in [1, 10]:\n",
    "                    init = \"cent\" if data_init else \"rand\"\n",
    "                    _mn = f\"clr{lr}_I{init}\"\n",
    "                    _cf = f\"{attack_type}_e{adv_alpha}_b{bounds}\"\n",
    "                    \n",
    "                    fig, axs = plt.subplots(1,2, figsize=(8,3))\n",
    "                    plot_experiment_instance(axs[0], hidden_units=100, data_init=data_init, center_lr=center_lr, \n",
    "                                             bound=bounds, temp_scale=1.0, attack_type=attack_type, adv_alpha=adv_alpha)\n",
    "                    plot_experiment_instance(axs[1], hidden_units=500, data_init=data_init, center_lr=center_lr, \n",
    "                                             bound=bounds, temp_scale=1.0, attack_type=attack_type, adv_alpha=adv_alpha)\n",
    "                    \n",
    "                    plt.savefig(f\"./outputs/15.2_observation/measure_hidden_units/{_mn};{_cf}.pdf\", bbox_inches=\"tight\")\n",
    "                    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "509db503",
   "metadata": {},
   "outputs": [],
   "source": [
    "asdasdasdasd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b59d4888",
   "metadata": {},
   "source": [
    "### Plot samples of adv examples "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2720dee6",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DistanceTransform_Epsilon(dtnn.DistanceTransformBase):\n",
    "    \n",
    "    def __init__(self, input_dim, num_centers, p=2, bias=False, epsilon=0.1, itemp=1):\n",
    "        super().__init__(input_dim, num_centers, p=2)\n",
    "        \n",
    "        nc = num_centers\n",
    "        if epsilon is not None:\n",
    "            nc += 1\n",
    "        self.scaler = nn.Parameter(torch.log(torch.ones(1, 1)*itemp))\n",
    "        self.bias = nn.Parameter(torch.ones(1, nc)*0) if bias else None\n",
    "        \n",
    "#         self.epsilon = epsilon\n",
    "        if epsilon is None:\n",
    "            self.epsilon = None\n",
    "        else:\n",
    "            self.epsilon = dtnn.EMA(mu=epsilon)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        dists = super().forward(x)\n",
    "        \n",
    "        if self.epsilon is not None:\n",
    "            #################################\n",
    "#             dists = torch.cat([dists, torch.ones(len(x), 1).to(x)*self.epsilon], dim=1)\n",
    "            #################################\n",
    "            if self.training:\n",
    "#                 mdist = dists.min().data\n",
    "#                 mdist = dists.max().data\n",
    "                mdist = dists.mean().data\n",
    "\n",
    "                self.epsilon(mdist)\n",
    "            dists = torch.cat([dists, torch.ones(len(x), 1).to(x)*self.epsilon.mu], dim=1)\n",
    "            #################################\n",
    "        \n",
    "        ## scale the dists\n",
    "        dists = 1-dists*torch.exp(self.scaler)\n",
    "    \n",
    "        if self.bias is not None: dists = dists+self.bias\n",
    "        return dists"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc1a8c63",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LocalMLP_epsilonsoftmax(nn.Module):\n",
    "    \n",
    "    def __init__(self, input_dim, hidden_dim, output_dim, epsilon=1.0, itemp=1):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.input_dim = input_dim\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.new_hidden_dim = 0\n",
    "        self.output_dim = output_dim\n",
    "        \n",
    "        self.layer0 = DistanceTransform_Epsilon(self.input_dim, self.hidden_dim, bias=False, epsilon=epsilon, itemp=itemp)\n",
    "        \n",
    "        hdim = self.hidden_dim\n",
    "        if epsilon is not None:\n",
    "            hdim += 1\n",
    "            \n",
    "#         self.scale_shift = dtnn.ScaleShift(hdim, scaler_init=10, shifter_init=0, scaler_const=True, shifter_const=True)\n",
    "        self.softmax = nn.Softmax(dim=-1)\n",
    "        self.layer1 = nn.Linear(hdim, self.output_dim, bias=False)\n",
    "    \n",
    "        self.temp_maximum = None\n",
    "        \n",
    "    def forward(self, x):\n",
    "        xo = self.layer0(x)\n",
    "        ## dropout here creates 0 actv (is relatively high), hence serves as noise --> does not work for high values\n",
    "#         xo = F.dropout(xo, p=0.001, training=self.training) ## use -inf as dropped value...\n",
    "#         xo = self.scale_shift(xo)\n",
    "        xo = self.softmax(xo)\n",
    "        self.temp_maximum = xo.data\n",
    "        \n",
    "        self.layer1.weight.data[:,-1]*=0.\n",
    "        xo = self.layer1(xo)\n",
    "        return xo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cec4396",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_model( hidden_units, data_init, center_lr):\n",
    "    \n",
    "    init = \"cent\" if data_init else \"rand\"\n",
    "    model_name = f\"dtesm_identity_I{init}_clrs{center_lr}_h{hidden_units}_mean\"\n",
    "    ckpt = torch.load(f\"{model_dir}/{model_name}.pth\")\n",
    "    accuracy = ckpt[\"acc\"]\n",
    "    \n",
    "    flows = [irf.Flatten(img_size=[1, 28, 28])]\n",
    "    backbone = nn.Sequential(*flows).to(device)\n",
    "    classifier = LocalMLP_epsilonsoftmax(784, hidden_units, 10).to(device)\n",
    "    model = nn.Sequential(backbone, classifier)\n",
    "    model.load_state_dict(ckpt[\"model\"])\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2f41df9",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = load_model(hidden_units=100, data_init=False, center_lr=0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "461f2c3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "model[1].layer0.bias ## not used"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76485f06",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, k in enumerate(attack_dict.keys()):\n",
    "    print(i, k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3127c495",
   "metadata": {},
   "outputs": [],
   "source": [
    "model[1].layer0.epsilon.mu[0] = 10."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cc24806",
   "metadata": {},
   "outputs": [],
   "source": [
    "atk_idx = 1\n",
    "epsilon = 9.0 ### alpha (as learning rate)\n",
    "\n",
    "fmodel = fb.PyTorchModel(model.eval(), bounds=(-10, 10), device=device)\n",
    "attack = attack_dict[list(attack_dict.keys())[atk_idx]]\n",
    "\n",
    "\n",
    "count = 0\n",
    "failed = 0\n",
    "rejected = 0\n",
    "x_rejected = 0\n",
    "for i, (xx, yy) in enumerate(test_loader): ## randomize test_loader ^^\n",
    "    xx = xx.to(device)\n",
    "    yy = yy.to(device)\n",
    "    break\n",
    "    \n",
    "### without adversarial\n",
    "# yout = model(xx)\n",
    "# reject_hid = model[1].temp_maximum.max(dim=1)[1] == model[1].hidden_dim\n",
    "# reject = reject_hid\n",
    "# x_rejected += int(reject.type(torch.float32).sum())\n",
    "\n",
    "### with adversarial\n",
    "unbound_advs, advs, success = attack(fmodel, xx, yy, epsilons=1.0)   \n",
    "grad = xx-unbound_advs\n",
    "grad = grad/(torch.norm(grad.view(xx.shape[0], -1), dim=1)[:, None, None, None])\n",
    "advs = (xx - grad*epsilon).clip(-10, 10)\n",
    "yout = model(advs)\n",
    "success = ~(yout.argmax(dim=1) == yy)\n",
    "\n",
    "# reject = model[1].temp_maximum.max(dim=1)[1] == model[1].hidden_dim\n",
    "# rejected += int(reject.type(torch.float32).sum())\n",
    "\n",
    "# fail = torch.bitwise_and(success, ~reject).type(torch.float32).sum()\n",
    "# failed += int(fail)    \n",
    "# count += len(xx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb2f81ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "advs.shape, advs.device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9096bb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# torch.norm(grad.view(xx.shape[0], -1), dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02b18303",
   "metadata": {},
   "outputs": [],
   "source": [
    "# advs[-2]\n",
    "grad.shape, xx.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "433b7803",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.nonzero(torch.isnan(advs).to(torch.float32).sum(dim=(1,2,3)) == 0.).reshape(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48b9715f",
   "metadata": {},
   "outputs": [],
   "source": [
    "model[1].layer0.epsilon.mu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dda4eb1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# xx, advs, grad = xx[:,0].cpu(), advs[:,0].cpu(), grad[:,0].cpu()\n",
    "# success = success.cpu().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccd43910",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_adv_atk(xx, grad, advs, success):\n",
    "    xx, advs, grad = xx[:,0].cpu(), advs[:,0].cpu(), grad[:,0].cpu()\n",
    "#     idx = torch.isnan(grad)\n",
    "\n",
    "#     non_nan_idx = torch.nonzero(torch.isnan(advs).to(torch.float32).sum(dim=(1,2,3)) == 0.).reshape(-1)\n",
    "#     assert len(non_nan_idx) >= 5, \"Most grads seems nan\"\n",
    "    \n",
    "        \n",
    "#     break\n",
    "    success = success.cpu().numpy()    \n",
    "    fig, axs = plt.subplots(5, 3, figsize=(6, 10))\n",
    "    for i, axx in enumerate(axs.reshape(-1, 3)):\n",
    "        im = axx[0].imshow(xx[i])\n",
    "        axx[0].tick_params(which = 'both', size = 0, labelsize = 0)\n",
    "        plt.colorbar(im)\n",
    "        _norm = torch.norm(xx[i]).item()\n",
    "        axx[0].set_xlabel(r\"$x$\"+f\"-norm:{_norm:.2f}\")\n",
    "\n",
    "        im = axx[1].imshow(grad[i])\n",
    "        axx[1].tick_params(which = 'both', size = 0, labelsize = 0)\n",
    "        plt.colorbar(im)\n",
    "        _norm = torch.norm(grad[i]).item()\n",
    "        fld = [\"✕\", \"✓\"][int(success[i])]\n",
    "        axx[1].set_xlabel(r\"$g$\"+f\" ;  fooled:{fld}\")\n",
    "\n",
    "        im = axx[2].imshow(advs[i])\n",
    "        axx[2].tick_params(which = 'both', size = 0, labelsize = 0)\n",
    "        plt.colorbar(im)\n",
    "        _norm = torch.norm(advs[i]).item()\n",
    "        axx[2].set_xlabel(f\"adv-norm:{_norm:.2f}\")\n",
    "#     plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcea1a11",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_adv_atk(xx, grad, advs, success)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efe6987c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_adverserial_rejection(model, epsilon, bounds, attack_str, xx, yy): ## bounds in [1, 10]\n",
    "    \n",
    "    fmodel = fb.PyTorchModel(model.eval(), bounds=[-100, 100], device=device) ## no bound, manually bounded \n",
    "    attack = attack_dict[attack_str]\n",
    "    \n",
    "    count = 0\n",
    "    failed = 0\n",
    "    rejected = 0\n",
    "    x_rejected = 0\n",
    "    dists_sum = 0\n",
    "    actv_sum = 0\n",
    "    if True:\n",
    "        xx = xx.to(device)\n",
    "        yy = yy.to(device)\n",
    "\n",
    "        yout = model(xx)\n",
    "        reject = model[1].temp_maximum.max(dim=1)[1] == model[1].hidden_dim\n",
    "        x_rejected += int(reject.type(torch.float32).sum())\n",
    "        \n",
    "        min_dist_cent = torch.cdist(xx.reshape(-1, 784), model[1].layer0.centers.data)\n",
    "        min_dists = min_dist_cent.min(dim=1)[0]\n",
    "        min_dists = min_dists.mean().item()\n",
    "        print(\"for x, dist\",min_dists)\n",
    "        max_neuron_p = model[1].temp_maximum[:,:-1].max(dim=1)[0]\n",
    "        max_neuron_p = max_neuron_p.mean().item()\n",
    "        print(\"for x, neuron_p\",max_neuron_p)\n",
    "        \n",
    "\n",
    "        unbound_advs, advs, success = attack(fmodel, xx, yy, epsilons=1.0)   \n",
    "        grad = xx-unbound_advs\n",
    "        grad = grad/(torch.norm(grad.view(xx.shape[0], -1), dim=1)[:, None, None, None])\n",
    "        advs = (xx - grad*epsilon).clip(*bounds)\n",
    "        yout = model(advs)\n",
    "        success = ~(yout.argmax(dim=1) == yy)\n",
    "        \n",
    "        reject = model[1].temp_maximum.max(dim=1)[1] == model[1].hidden_dim\n",
    "        rejected += int(reject.type(torch.float32).sum())\n",
    "\n",
    "        fail = torch.bitwise_and(success, ~reject).type(torch.float32)\n",
    "        failed += int(fail.sum())    \n",
    "        count += len(xx)\n",
    "        \n",
    "        min_dist_cent = torch.cdist(advs.reshape(-1, 784), model[1].layer0.centers.data)\n",
    "        min_dists = min_dist_cent.min(dim=1)[0]\n",
    "        min_dists = min_dists.mean().item()\n",
    "        print(\"for adv, min_dist\",min_dists)\n",
    "        max_neuron_p = model[1].temp_maximum[:,:-1].max(dim=1)[0]\n",
    "        max_neuron_p = max_neuron_p.mean().item()\n",
    "        print(\"for adv, max_neuron\",max_neuron_p)\n",
    "        \n",
    "#     return count, failed, rejected, x_rejected, dists_sum, actv_sum, xx, grad, advs, fail## sent as success\n",
    "    return count, failed, rejected, x_rejected, dists_sum, actv_sum, xx, xx-unbound_advs, advs, fail## sent as success"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6eb661b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyze_adversarial_samples(ax, hidden_units, data_init, center_lr, \n",
    "                             bound=10, temp_scale=1.0, attack_type=\"FGSM\", adv_alpha=0.5):\n",
    "    \n",
    "    init = \"cent\" if data_init else \"rand\"\n",
    "    model_name = f\"dtesm_identity_I{init}_clrs{center_lr}_h{hidden_units}_mean\"\n",
    "    ckpt = torch.load(f\"{model_dir}/{model_name}.pth\")\n",
    "    accuracy = ckpt[\"acc\"]\n",
    "    \n",
    "    observation_dir = f\"outputs/15.1_evaluating_models/{model_name}/\"\n",
    "    if not os.path.exists(f'{observation_dir}/experiments_data.pkl'):\n",
    "        print(observation_dir, \"does not exist\")\n",
    "        raise ValueError(\"Given parameter does not have experiments\")\n",
    "        \n",
    "    center_lr, bound, temp_scale, adv_alpha = float(center_lr), int(bound), float(temp_scale), float(adv_alpha)\n",
    "    \n",
    "    config = f\"{attack_type}_e{adv_alpha}_b{bound}_ts{temp_scale}\"\n",
    "#     config = f\"{attack_type}_e{adv_alpha}_b{bound}\"\n",
    "\n",
    "    with open(f'{observation_dir}/experiments_data.pkl', 'rb') as handle:\n",
    "        actv_data_dict = pickle.load(handle)\n",
    "    data = actv_data_dict[config]\n",
    "    \n",
    "    #     print(test_count)\n",
    "    min_eps_at, max_eps_at = data[0,0], data[-1,0]\n",
    "    opt_eps_at = data[data[:,1].argmin(),0]\n",
    "    \n",
    "    \n",
    "    ##### plot after each experiment\n",
    "    test_count = data[0,2]\n",
    "    ax.plot(data[:,0], data[:,1], lw=2, label=\"measure\", marker='.')\n",
    "    ax.plot(data[:,0], data[:,3]/test_count, linestyle=\"dashed\", label=\"failed\")\n",
    "    ax.plot(data[:,0], data[:,4]/test_count, linestyle=\"dotted\", label=\"rejected\")\n",
    "    ax.plot(data[:,0], data[:,5]/test_count, linestyle=\"dotted\", label=\"x_rejected\")\n",
    "    ax.plot(data[:,0], data[:,6], linestyle=\"dashdot\", label=\"x_accuracy\")\n",
    "#     ax.set_xlabel(f\"{model_name[20:]}\\n{config}   Acc:{accuracy}\")\n",
    "    \n",
    "    _mn = f\"init:{init} clr:{center_lr} nh:{hidden_units} acc:{accuracy:.1f}\"\n",
    "    _cf = f\"{attack_type} \"+r\"$\\alpha$\"+f\":{int(adv_alpha)} b:[{-int(bound)}, {int(bound)}]\"\n",
    "    ax.set_xlabel(r\"$\\epsilon$ for \"+f\"{_cf}\\n{_mn}\")\n",
    "#     ax.set_xlabel(_cf)\n",
    "#     ax.set_ylabel(_mn)\n",
    "    \n",
    "    \n",
    "    ax.legend()\n",
    "    \n",
    "#     ax.set_ylabel(f\"{data[:,1].min():.3f}@e={data[data[:,1].argmin(),0]:.3f}\")\n",
    "    ax.hlines(data[:,1].min(), data[0,0], data[-1,0], linestyle='dashed', lw=0.5, color='k')\n",
    "    ax.hlines(data[-1,1], data[0,0], data[-1,0], linestyle='dotted', lw=0.5, color='b')\n",
    "    \n",
    "    ax.set_ylim(0,1)\n",
    "#     plt.show()\n",
    "    plt.savefig(f\"./outputs/15.2_observation/adv_eg_{model_name[15:]}_{config}.pdf\")\n",
    "    \n",
    "\n",
    "    flows = [irf.Flatten(img_size=[1, 28, 28])]\n",
    "    backbone = nn.Sequential(*flows).to(device)\n",
    "    classifier = LocalMLP_epsilonsoftmax(784, hidden_units, 10).to(device)\n",
    "    model = nn.Sequential(backbone, classifier)\n",
    "    model.load_state_dict(ckpt[\"model\"])\n",
    "    \n",
    "    for _xx, _yy in test_loader:\n",
    "        break\n",
    "        \n",
    "    ### eps at <95% between min and max=1(take for metric)\n",
    "    mask = np.nonzero(np.logical_and(data[:, 1]>0.98, data[:, 0] < opt_eps_at))[0]\n",
    "#     print(mask)\n",
    "    min_eps_at = data[mask[-1], 0]\n",
    "    print(\"min\", min_eps_at)\n",
    "    model[1].layer0.epsilon.mu[0] = min_eps_at\n",
    "    count, failed, rejected, x_rejected, dists_sum, actv_sum, xx, grad, advs, success = get_adverserial_rejection(model, \n",
    "                                                                adv_alpha, (-bound, bound), attack_type, _xx, _yy)\n",
    "    plot_adv_atk(xx, grad, advs, success)\n",
    "    plt.savefig(f\"./outputs/15.2_observation/adv_eg_{model_name[15:]}_{config}_eps{min_eps_at:.2f}_sample.pdf\", bbox_inches=\"tight\")\n",
    "    plt.show()\n",
    "    \n",
    "    \n",
    "#     print(dists_sum/count, actv_sum/count)\n",
    "    print(\"optimal\", opt_eps_at)\n",
    "    model[1].layer0.epsilon.mu[0] = opt_eps_at\n",
    "    count, failed, rejected, x_rejected, dists_sum, actv_sum, xx, grad, advs, success = get_adverserial_rejection(model, \n",
    "                                                                adv_alpha, (-bound, bound), attack_type, _xx, _yy)\n",
    "    plot_adv_atk(xx, grad, advs, success)\n",
    "    plt.savefig(f\"./outputs/15.2_observation/adv_eg_{model_name[15:]}_{config}_eps{opt_eps_at:.2f}_sample.pdf\", bbox_inches=\"tight\")\n",
    "    plt.show()\n",
    "    \n",
    "    \n",
    "    mask = np.nonzero(np.logical_and(data[:, 1]>(0.98*data[-1,1]), data[:, 0] > opt_eps_at))[0]\n",
    "#     print(mask)\n",
    "    max_eps_at = data[mask[0], 0]\n",
    "    print(\"max\", max_eps_at)\n",
    "    model[1].layer0.epsilon.mu[0] = max_eps_at\n",
    "    count, failed, rejected, x_rejected, dists_sum, actv_sum, xx, grad, advs, success = get_adverserial_rejection(model, \n",
    "                                                                adv_alpha, (-bound, bound), attack_type, _xx, _yy)\n",
    "    plot_adv_atk(xx, grad, advs, success)\n",
    "    plt.savefig(f\"./outputs/15.2_observation/adv_eg_{model_name[15:]}_{config}_eps{max_eps_at:.2f}_sample.pdf\", bbox_inches=\"tight\")\n",
    "#     print(dists_sum/count, actv_sum/count)    \n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cf952a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# len(\"dtesm_identity_\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "505726da",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(1,1, figsize=(4,4))\n",
    "analyze_adversarial_samples(axs, hidden_units=100, data_init=True, center_lr=0.01, \n",
    "                            bound=10, temp_scale=1.0, attack_type=\"FGM\", adv_alpha=20.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "649c9f21",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(1,1, figsize=(4,4))\n",
    "analyze_adversarial_samples(axs, hidden_units=100, data_init=False, center_lr=0.01, \n",
    "                            bound=10, temp_scale=1.0, attack_type=\"FGM\", adv_alpha=20.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed1bf6d7",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(1,1, figsize=(4,4))\n",
    "analyze_adversarial_samples(axs, hidden_units=500, data_init=True, center_lr=0.01, \n",
    "                            bound=1, temp_scale=1.0, attack_type=\"LinfAdamPGD\", adv_alpha=9.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6e316ed",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(1,1, figsize=(4,4))\n",
    "analyze_adversarial_samples(axs, hidden_units=500, data_init=False, center_lr=0.01, \n",
    "                            bound=1, temp_scale=1.0, attack_type=\"LinfAdamPGD\", adv_alpha=9.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "225a3a17",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
