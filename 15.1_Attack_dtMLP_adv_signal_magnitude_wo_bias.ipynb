{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5263a99",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import copy\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "# from mpl_toolkits.mplot3d import Axes3D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab15e189",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from torchvision import datasets, transforms as T\n",
    "from torch.utils import data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83a571ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "import os, time, sys, random\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b4143d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import foolbox as fb\n",
    "import foolbox.attacks as fa\n",
    "\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbdb9640",
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.path.append(\"./Input-Invex-Neural-Network/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fac3e89b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import dtnnlib as dtnn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9ee59a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nflib\n",
    "from nflib.flows import SequentialFlow, ActNorm, ActNorm2D, BatchNorm1DFlow, BatchNorm2DFlow\n",
    "import nflib.res_flow as irf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4fd54dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "mnist_transform = T.Compose([\n",
    "    T.ToTensor(),\n",
    "    T.Normalize(\n",
    "        mean=0.5,\n",
    "        std=0.5,\n",
    "    ),\n",
    "])\n",
    "\n",
    "train_dataset = datasets.FashionMNIST(root=\"data/\", train=True, download=True, transform=mnist_transform)\n",
    "test_dataset = datasets.FashionMNIST(root=\"data/\", train=False, download=True, transform=mnist_transform)\n",
    "# train_dataset = datasets.MNIST(root=\"data/\", train=True, download=True, transform=mnist_transform)\n",
    "# test_dataset = datasets.MNIST(root=\"data/\", train=False, download=True, transform=mnist_transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4b78d5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset.data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "800277ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 1000\n",
    "train_loader = data.DataLoader(dataset=train_dataset, num_workers=4, batch_size=batch_size, shuffle=True)\n",
    "test_loader = data.DataLoader(dataset=test_dataset, num_workers=4, batch_size=batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3bad2b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda:0\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ae133e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "for xx, yy in train_loader:\n",
    "    print(xx.shape)\n",
    "#     xx, yy = xx.view(-1,28*28).to(device), yy.to(device)\n",
    "    xx, yy = xx.to(device), yy.to(device)\n",
    "    print(xx.shape, yy.shape)\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c1c0e08",
   "metadata": {},
   "source": [
    "## Train Test method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b7a979b",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_dir = \"outputs/15.0_models\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f797626",
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68bd8415",
   "metadata": {},
   "source": [
    "## Adverserial Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6ee25d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "attack_dict = {\n",
    "    \"FGSM\": fa.FGSM(), ## LinfFastGradientAttack\n",
    "    \"FGM\": fa.FGM(), ## L2FastGradientAttack\n",
    "    \"L2PGD\": fa.L2PGD(steps=20), ## higher steps (>10) better ??_!!\n",
    "    \"LinfPGD\": fa.LinfPGD(steps=20), ## PGD\n",
    "    \"L1AdamPGD\": fa.L1AdamPGD(steps=20, adam_beta1=0.8, adam_beta2=0.95),\n",
    "    \"L2AdamPGD\": fa.L2AdamPGD(steps=20, adam_beta1=0.8, adam_beta2=0.95),\n",
    "    \"LinfAdamPGD\": fa.LinfAdamPGD(steps=20, adam_beta1=0.8, adam_beta2=0.95),\n",
    "    \"L2AdamBasic\": fa.L2AdamBasicIterativeAttack(steps=10), ## default steps\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25bb6b9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "attack_dict.keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4fe86b78",
   "metadata": {},
   "source": [
    "## Model\n",
    "copied from prev..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2720dee6",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DistanceTransform_Epsilon(dtnn.DistanceTransformBase):\n",
    "    \n",
    "    def __init__(self, input_dim, num_centers, p=2, bias=False, epsilon=0.1, itemp=1):\n",
    "        super().__init__(input_dim, num_centers, p=2)\n",
    "        \n",
    "        nc = num_centers\n",
    "        if epsilon is not None:\n",
    "            nc += 1\n",
    "        self.scaler = nn.Parameter(torch.log(torch.ones(1, 1)*itemp))\n",
    "        self.bias = nn.Parameter(torch.ones(1, nc)*0) if bias else None\n",
    "        \n",
    "#         self.epsilon = epsilon\n",
    "        if epsilon is None:\n",
    "            self.epsilon = None\n",
    "        else:\n",
    "            self.epsilon = dtnn.EMA(mu=epsilon)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        dists = super().forward(x)\n",
    "        \n",
    "        if self.epsilon is not None:\n",
    "            #################################\n",
    "#             dists = torch.cat([dists, torch.ones(len(x), 1).to(x)*self.epsilon], dim=1)\n",
    "            #################################\n",
    "            if self.training:\n",
    "#                 mdist = dists.min().data\n",
    "#                 mdist = dists.max().data\n",
    "                mdist = dists.mean().data\n",
    "\n",
    "                self.epsilon(mdist)\n",
    "            dists = torch.cat([dists, torch.ones(len(x), 1).to(x)*self.epsilon.mu], dim=1)\n",
    "            #################################\n",
    "        \n",
    "        ## scale the dists\n",
    "        dists = 1-dists*torch.exp(self.scaler)\n",
    "    \n",
    "        if self.bias is not None: dists = dists+self.bias\n",
    "        return dists"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc1a8c63",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LocalMLP_epsilonsoftmax(nn.Module):\n",
    "    \n",
    "    def __init__(self, input_dim, hidden_dim, output_dim, epsilon=1.0, itemp=1):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.input_dim = input_dim\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.new_hidden_dim = 0\n",
    "        self.output_dim = output_dim\n",
    "        \n",
    "        self.layer0 = DistanceTransform_Epsilon(self.input_dim, self.hidden_dim, bias=False, epsilon=epsilon, itemp=itemp)\n",
    "        \n",
    "        hdim = self.hidden_dim\n",
    "        if epsilon is not None:\n",
    "            hdim += 1\n",
    "            \n",
    "#         self.scale_shift = dtnn.ScaleShift(hdim, scaler_init=10, shifter_init=0, scaler_const=True, shifter_const=True)\n",
    "        self.softmax = nn.Softmax(dim=-1)\n",
    "        self.layer1 = nn.Linear(hdim, self.output_dim, bias=False)\n",
    "    \n",
    "        self.temp_maximum = None\n",
    "        \n",
    "    def forward(self, x):\n",
    "        xo = self.layer0(x)\n",
    "        ## dropout here creates 0 actv (is relatively high), hence serves as noise --> does not work for high values\n",
    "#         xo = F.dropout(xo, p=0.001, training=self.training) ## use -inf as dropped value...\n",
    "#         xo = self.scale_shift(xo)\n",
    "        xo = self.softmax(xo)\n",
    "        self.temp_maximum = xo.data\n",
    "        \n",
    "        self.layer1.weight.data[:,-1]*=0.\n",
    "        xo = self.layer1(xo)\n",
    "        return xo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cec4396",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_model( hidden_units, data_init, center_lr):\n",
    "    \n",
    "    init = \"cent\" if data_init else \"rand\"\n",
    "    model_name = f\"dtesm_identity_I{init}_clrs{center_lr}_h{hidden_units}_mean\"\n",
    "    ckpt = torch.load(f\"{model_dir}/{model_name}.pth\")\n",
    "    accuracy = ckpt[\"acc\"]\n",
    "    \n",
    "    flows = [irf.Flatten(img_size=[1, 28, 28])]\n",
    "    backbone = nn.Sequential(*flows).to(device)\n",
    "    classifier = LocalMLP_epsilonsoftmax(784, hidden_units, 10).to(device)\n",
    "    model = nn.Sequential(backbone, classifier)\n",
    "    model.load_state_dict(ckpt[\"model\"])\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2f41df9",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = load_model(hidden_units=100, data_init=True, center_lr=0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "461f2c3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "model[1].layer0.bias ## not used"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15c8d594",
   "metadata": {},
   "outputs": [],
   "source": [
    "invbackbone = SequentialFlow([*model[0]]).to(device)\n",
    "            \n",
    "_, axs = plt.subplots(5, 5, figsize=(10, 10))\n",
    "axs = axs.flatten()\n",
    "with torch.no_grad():\n",
    "    c = invbackbone.inverse(model[1].layer0.centers.data).data.cpu().numpy().reshape(-1, 28,28)\n",
    "imgs = c[:len(axs)]\n",
    "for img, ax in zip(imgs, axs):\n",
    "    im = ax.imshow(img)\n",
    "    ax.set_axis_off()\n",
    "    plt.colorbar(im)\n",
    "\n",
    "# plt.savefig(f\"{observation_dir}/centers_sample.jpg\", bbox_inches='tight')\n",
    "# plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1e37057",
   "metadata": {},
   "outputs": [],
   "source": [
    "_, axs = plt.subplots(2, 5, figsize=(10, 4))\n",
    "axs = axs.reshape(-1)\n",
    "cls_rep = model[1].layer1.weight[:,:-1].argmax(dim=0)\n",
    "for i in range(10):\n",
    "    idx = torch.nonzero(cls_rep == i).cpu()\n",
    "    imgs = c[idx].reshape(-1, 1, 28, 28)\n",
    "    img = imgs.mean(axis=(0,1))\n",
    "    if imgs.shape[0]==1: print(\"single center at:\",i)\n",
    "    im = axs[i].imshow(img)\n",
    "    axs[i].set_axis_off()\n",
    "    plt.colorbar(im)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76485f06",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, k in enumerate(attack_dict.keys()):\n",
    "    print(i, k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cc24806",
   "metadata": {},
   "outputs": [],
   "source": [
    "atk_idx = 1 ## ^^\n",
    "epsilon = 9.0\n",
    "\n",
    "#######################################\n",
    "fmodel = fb.PyTorchModel(model.eval(), bounds=(-10, 10), device=device)\n",
    "attack = attack_dict[list(attack_dict.keys())[atk_idx]]\n",
    "\n",
    "\n",
    "count = 0\n",
    "failed = 0\n",
    "rejected = 0\n",
    "x_rejected = 0\n",
    "for i, (xx, yy) in enumerate(test_loader): ## randomize test_loader ^^\n",
    "    xx = xx.to(device)\n",
    "    yy = yy.to(device)\n",
    "    break\n",
    "    \n",
    "### without adversarial\n",
    "# yout = model(xx)\n",
    "# reject_hid = model[1].temp_maximum.max(dim=1)[1] == model[1].hidden_dim\n",
    "# reject = reject_hid\n",
    "# x_rejected += int(reject.type(torch.float32).sum())\n",
    "\n",
    "### with adversarial\n",
    "unbound_advs, advs, success = attack(fmodel, xx, yy, epsilons=1.0)   \n",
    "grad = xx-unbound_advs\n",
    "grad = grad/(torch.norm(grad.view(xx.shape[0], -1), dim=1)[:, None, None, None])\n",
    "advs = (xx - grad*epsilon).clip(-10, 10)\n",
    "yout = model(advs)\n",
    "success = ~(yout.argmax(dim=1) == yy)\n",
    "\n",
    "# reject = model[1].temp_maximum.max(dim=1)[1] == model[1].hidden_dim\n",
    "# rejected += int(reject.type(torch.float32).sum())\n",
    "\n",
    "# fail = torch.bitwise_and(success, ~reject).type(torch.float32).sum()\n",
    "# failed += int(fail)    \n",
    "# count += len(xx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb2f81ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "advs.shape, advs.device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dda4eb1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "xx, advs, grad = xx[:,0].cpu(), advs[:,0].cpu(), grad[:,0].cpu()\n",
    "success = success.cpu().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccd43910",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(8, 6, figsize=(12, 14))\n",
    "for i, axx in enumerate(axs.reshape(-1, 3)):\n",
    "    im = axx[0].imshow(xx[i])\n",
    "    axx[0].tick_params(which = 'both', size = 0, labelsize = 0)\n",
    "    plt.colorbar(im)\n",
    "    _norm = torch.norm(xx[i]).item()\n",
    "    axx[0].set_xlabel(f\"x > norm:{_norm:.2f}\")\n",
    "    \n",
    "    im = axx[1].imshow(grad[i])\n",
    "    axx[1].tick_params(which = 'both', size = 0, labelsize = 0)\n",
    "    plt.colorbar(im)\n",
    "    _norm = torch.norm(grad[i]).item()\n",
    "    axx[1].set_xlabel(f\"g > succ:{success[i]}\")\n",
    "    \n",
    "    im = axx[2].imshow(advs[i])\n",
    "    axx[2].tick_params(which = 'both', size = 0, labelsize = 0)\n",
    "    plt.colorbar(im)\n",
    "    _norm = torch.norm(advs[i]).item()\n",
    "    axx[2].set_xlabel(f\"ad > norm:{_norm:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "880233a0",
   "metadata": {},
   "source": [
    "### Modified adverserial attack\n",
    "- to attack based on normalized magnitude of adverserial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47f131fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "attack_dict.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88bf71b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_adverserial_rejection(model, epsilon, bounds, attack_str): ## bounds in [1, 10]\n",
    "    fmodel = fb.PyTorchModel(model.eval(), bounds=[-100, 100], device=device) ## no bound, manually bounded \n",
    "\n",
    "    attack = attack_dict[attack_str]\n",
    "    \n",
    "    count = 0\n",
    "    failed = 0\n",
    "    rejected = 0\n",
    "    x_rejected = 0\n",
    "    \n",
    "    correct = 0\n",
    "    for i, (xx, yy) in enumerate(test_loader):\n",
    "        xx = xx.to(device)\n",
    "        yy = yy.to(device)\n",
    "\n",
    "        yout = model(xx)\n",
    "        _, predicted = yout.max(1)\n",
    "        correct += predicted.eq(yy).sum().item()\n",
    "        reject = model[1].temp_maximum.max(dim=1)[1] == model[1].hidden_dim\n",
    "        x_rejected += int(reject.type(torch.float32).sum())\n",
    "\n",
    "        unbound_advs, advs, success = attack(fmodel, xx, yy, epsilons=1.0)   \n",
    "        grad = xx-unbound_advs\n",
    "        grad = grad/(torch.norm(grad.view(xx.shape[0], -1), dim=1)[:, None, None, None])\n",
    "        advs = (xx - grad*epsilon).clip(*bounds)\n",
    "        yout = model(advs)\n",
    "        success = ~(yout.argmax(dim=1) == yy)\n",
    "        \n",
    "        reject = model[1].temp_maximum.max(dim=1)[1] == model[1].hidden_dim\n",
    "        rejected += int(reject.type(torch.float32).sum())\n",
    "\n",
    "        fail = torch.bitwise_and(success, ~reject).type(torch.float32).sum()\n",
    "        failed += int(fail)    \n",
    "        count += len(xx)\n",
    "\n",
    "    return count, failed, rejected, x_rejected, correct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e217bc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def search_minimal_adverserial(model, attack_str, adv_epsilon, bounds, training_epsilon, inner_search_iter=2):\n",
    "    mus = training_epsilon*(2**torch.linspace(-2, 1, steps=10))\n",
    "\n",
    "    eps_measure_dict = {}\n",
    "    \n",
    "    #################################################\n",
    "    max_xrej, mxe = -1, None\n",
    "    max_failed, mfe = -1, None\n",
    "    for mu in mus:\n",
    "        model[1].layer0.epsilon.mu[0] = mu\n",
    "        count, failed, rejected, x_rejected, correct = get_adverserial_rejection(model, adv_epsilon, bounds, attack_str)\n",
    "        measure = (failed+x_rejected)/count ## ^ maximize\n",
    "#         print(\"eps:\", mu, measure, f\"failed: {failed} x_rej: {x_rejected}\")\n",
    "        accuracy = correct/count\n",
    "        eps_measure_dict[float(mu)] = [measure, count, failed, rejected, x_rejected, accuracy]\n",
    "\n",
    "        if x_rejected >= max_xrej:\n",
    "            max_xrej = x_rejected\n",
    "            mxe = mu\n",
    "        if failed > max_failed:\n",
    "            max_failed = failed\n",
    "            mfe = mu\n",
    "    lowval, highval = mxe, mfe\n",
    "    #################################################\n",
    "    for _ in range(inner_search_iter):\n",
    "#         print()\n",
    "        mus = torch.linspace(lowval, highval, 22)[1:-1]\n",
    "        min_measure, idx = 9e9, None \n",
    "        for i, mu in enumerate(mus):\n",
    "            model[1].layer0.epsilon.mu[0] = mu\n",
    "            count, failed, rejected, x_rejected, correct = get_adverserial_rejection(model, adv_epsilon, bounds, attack_str)\n",
    "            measure = (failed+x_rejected)/count ## ^ maximize\n",
    "#             print(\"eps:\",mu , measure, f\"failed: {failed} x_rej: {x_rejected}\")\n",
    "            accuracy = correct/count\n",
    "            eps_measure_dict[float(mu)] = [measure, count, failed, rejected, x_rejected, accuracy]\n",
    "\n",
    "            if measure < min_measure:\n",
    "                min_measure = measure\n",
    "                idx = i\n",
    "                \n",
    "        gap = mus[1]-mus[0]\n",
    "        lowval, highval = mus[idx]-gap, mus[idx]+gap\n",
    "                \n",
    "    all_data = []\n",
    "    for k, v in sorted(eps_measure_dict.items()):\n",
    "        all_data.append([k, *v])\n",
    "#         print(all_data[-1])\n",
    "    all_data = np.array(all_data)\n",
    "    print(\"Search Finished\\n\")\n",
    "    return all_data, [\"measure\", \"count\", \"failed\", \"rejected\", \"x_rejected\", \"accuracy\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5316d89",
   "metadata": {},
   "source": [
    "## Benchmark Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70087c64",
   "metadata": {},
   "outputs": [],
   "source": [
    "# breakall=False\n",
    "for center_lr_scaler in [1.0, 0.01]:\n",
    "    for hidden_units in [100, 500]:\n",
    "#     for hidden_units in [100]:\n",
    "        for data_init in [True, False]:\n",
    "            init = \"rand\"\n",
    "            if data_init:\n",
    "                init = \"cent\"\n",
    "            model_name = f\"dtesm_identity_I{init}_clrs{center_lr_scaler}_h{hidden_units}_mean\"\n",
    "            ########################################\n",
    "            print(model_name)\n",
    "            \n",
    "            flows = [\n",
    "                irf.Flatten(img_size=[1, 28, 28]),\n",
    "                    ]\n",
    "            backbone = nn.Sequential(*flows).to(device)\n",
    "\n",
    "            classifier = LocalMLP_epsilonsoftmax(784, hidden_units, 10).to(device)\n",
    "            model = nn.Sequential(backbone, classifier)\n",
    "            print(\"num_parameters\", sum([p.numel() for p in model.parameters()]))\n",
    "            \n",
    "            ckpt = torch.load(f\"{model_dir}/{model_name}.pth\")\n",
    "            model.load_state_dict(ckpt[\"model\"])\n",
    "            \n",
    "            invbackbone = SequentialFlow([*backbone]).to(device)\n",
    "            #######################################\n",
    "            training_epsilon = model[1].layer0.epsilon.mu.item()\n",
    "            backup_scaler = model[1].layer0.scaler.data\n",
    "            \n",
    "            \n",
    "            observation_dir = f\"outputs/15.1_evaluating_models/{model_name}/\"\n",
    "            os.makedirs(observation_dir, exist_ok=True)\n",
    "            \n",
    "            if os.path.exists(f'{observation_dir}/experiments_data.pkl'):\n",
    "                print(\"Experiment Alreay Finished... \\n NEXT \\n\")\n",
    "                continue\n",
    "                \n",
    "            #######################################\n",
    "            _, axs = plt.subplots(5, 5, figsize=(10, 10))\n",
    "            axs = axs.flatten()\n",
    "            with torch.no_grad():\n",
    "                c = invbackbone.inverse(model[1].layer0.centers.data).data.cpu().numpy().reshape(-1, 28,28)\n",
    "            imgs = c[:len(axs)]\n",
    "            for img, ax in zip(imgs, axs):\n",
    "                im = ax.imshow(img)\n",
    "                ax.set_axis_off()\n",
    "                plt.colorbar(im)\n",
    "    \n",
    "            plt.savefig(f\"{observation_dir}/centers_sample.jpg\", bbox_inches='tight')\n",
    "            plt.close()\n",
    "            #######################################\n",
    "            _, axs = plt.subplots(2, 5, figsize=(10, 4))\n",
    "            axs = axs.reshape(-1)\n",
    "            cls_rep = model[1].layer1.weight[:,:-1].argmax(dim=0)\n",
    "            for i in range(10):\n",
    "                idx = torch.nonzero(cls_rep == i).cpu()\n",
    "                imgs = c[idx].reshape(-1, 1, 28, 28)\n",
    "                img = imgs.mean(axis=(0,1))\n",
    "                if imgs.shape[0]==1: print(\"single center at:\",i)\n",
    "                im = axs[i].imshow(img)\n",
    "                axs[i].set_axis_off()\n",
    "                plt.colorbar(im) \n",
    "                axs[i].set_xlabel(test_dataset.classes[i])\n",
    "\n",
    "            plt.savefig(f\"{observation_dir}/centers_mean.jpg\", bbox_inches='tight')\n",
    "            plt.close()\n",
    "            #######################################\n",
    "            print(\"INITIATING ADVERSARIAL ATTACK\")\n",
    "            adv_data_dict = {\"metadata\":\n",
    "                    {\"training_epsilon\": training_epsilon,\n",
    "                     \"learned_scaler\": backup_scaler[0,0].item()}\n",
    "                }\n",
    "            #######################################\n",
    "#             for temp_scale in [1.0, 0.25, 4.0]:\n",
    "            for temp_scale in [1.0]:\n",
    "                for bound in [10, 1]:\n",
    "#                     for atk_str in attack_dict.keys():\n",
    "                    for atk_str in random.sample(list(attack_dict.keys()), 3):\n",
    "                        for adv in [0.5, 1.0, 3.0, 9.0, 20.0]:\n",
    "                            config = f\"{atk_str}_e{adv}_b{bound}_ts{temp_scale}\"\n",
    "                            print(config)\n",
    "                            model[1].layer0.scaler.data = backup_scaler*temp_scale\n",
    "                            data, keys = search_minimal_adverserial(model, atk_str, adv, (-bound, bound), training_epsilon, 2)\n",
    "                            adv_data_dict[config] = data\n",
    "\n",
    "                            ##### plot after each experiment\n",
    "                            test_count = data[0,2]\n",
    "                            plt.plot(data[:,0], data[:,1], lw=2, label=\"measure\", marker='.')\n",
    "                            plt.plot(data[:,0], data[:,3]/test_count, linestyle=\"dashed\", label=\"failed\")\n",
    "                            plt.plot(data[:,0], data[:,4]/test_count, linestyle=\"dotted\", label=\"rejected\")\n",
    "                            plt.plot(data[:,0], data[:,5]/test_count, linestyle=\"dotted\", label=\"x_rejected\")\n",
    "                            plt.plot(data[:,0], data[:,6], linestyle=\"dashdot\", label=\"x_accuracy\")\n",
    "                            \n",
    "                            _mn = f\"init:{init} clr:{center_lr_scaler} nh:{hidden_units} acc:{data[-1,6]:.1f}\"\n",
    "                            _cf = f\"{attack_type} \"+r\"$\\alpha$\"+f\":{int(adv_alpha)} b:[{-int(bound)}, {int(bound)}]\"\n",
    "                            plt.xlabel(r\"$\\epsilon$ for \"+f\"{_cf}\\n{_mn}\")\n",
    "                            plt.legend()\n",
    "                            plt.savefig(f\"{observation_dir}/obs_{config}.png\", bbox_inches='tight')\n",
    "                            plt.close()\n",
    "                            \n",
    "#                         break\n",
    "#                     break\n",
    "#                 break\n",
    "            with open(f'{observation_dir}/experiments_data.pkl', 'wb') as f:\n",
    "                pickle.dump(adv_data_dict, f, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "            #######################################\n",
    "            \n",
    "            #######################################\n",
    "            "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
